---
layout: newsletter
slug: 2018-06-06-client
---

Hello!  In this week's newsletter we announce an upcoming webinar to introduce our newest report (coming soon!), take a look at recent developments in quantum computing, and discuss the continuing evolution of chatbots.

---

##  Letting Physics do the Math

Until recently, "analog computing" may have smacked of obsolescence, but with the next wave of computing hardware, physical systems that run algorithms by letting Mother Nature run her course are making a come-back. 

The most visible examples originate with quantum information technology, where increasingly mature technology platforms are attracting considerable public and private sector financing. Last month's [expert briefing](https://energycommerce.house.gov/hearings/disrupter-series-quantum-computing/) to members of the House Energy Subcommittee featured cogent perspectives on the importance of quantum information technology for research, industry, and, not least, national security. For a light introduction to its potential impact on AI in particular, we recommend [this article](https://www.quantamagazine.org/job-one-for-quantum-computers-boost-artificial-intelligence-20180129/) in Quanta Magazine, while Doug Finke's [Quantum Computing Report](https://quantumcomputingreport.com/) provides a much-needed resource on current affairs in a sector that is as equally notorious for its deep technical challenges as for its disruptive potential. 

While universal quantum computing remains elusive, quantum mechanical hardware accelerators are becoming a thing of the present: if your optimization problem gives you confusing nightmares about statistical mechanics (physicists, raise your hands!), then you might find [D-Wave's technology](https://www.dwavesys.com/home) inspiring. The Canadian startup's "Quantum Processing Unit" (QPU) encodes qubits in the magnetic moment of currents flowing inside of microscopic superconducting circuits, known as SQUIDs, which may interact with their nearest neighbors on a 2D grid architecture. 

The system is programmed by initializing the system with the desired potential energy landscape and letting it evolve to its lowest energy state. The approach, known as quantum annealing, essentially conducts an actual physics experiment to perform optimization, rather than to merely simulate annealing. 

The spectrum of otherwise computationally expensive optimization problems that can be solved in this way is broad, though the Quantum Computing StackExchange will get you started with a quantum annealing ["Hello World."](https://quantumcomputing.stackexchange.com/questions/1451/how-do-you-write-a-simple-program-for-a-d-wave-device) 

Another striking example of a physics-based computing platform was created by a collaboration led by Yichen Shen and Nicholas Harris at MIT, who recognized that the highly sophisticated optical circuits engendered by modern information technology can enable an all-optical implementation of neural networks. 

In [a paper published last year](https://www.nature.com/articles/nphoton.2017.93), they demonstrate a neural network performing vowel recognition based on light propagating through a photonic integrated circuit. Here, the evaluation of the various associated matrix multiplications occurs literally at the speed of light, and at considerable energy savings. The paper is symptomatic of a resurging interest in analog optical information processing, which is a decades-old idea that had somewhat fallen out of favor as it failed to keep pace with digital computers.

---

## The Continuing Evolution of Chatbots

Many companies have adopted chatbots to date, especially in the [customer service space](https://medium.com/the-mission/10-real-examples-how-brands-are-using-chatbot-for-customer-service-4fbb5e4617f3).  These chatbots, instead of being based on sophisticated machine learning algorithms, are typically comprised of relatively straight-forward decision trees based on business specific inputs.  Despite not typically utilizing neural networks or other more technically complicated algorithms, chatbots have fundamentally changed the ways in which we interact with and perceive machines.  

We still have a long way to go in terms of how consumers understand and [build trust](https://techcrunch.com/2018/05/24/family-claims-their-echo-sent-a-private-conversation-to-a-random-contact/) with these agents.  However, especially in enterprise settings, they are changing the face of customer service.  Autodesk recently released a new and improved version of their customer service chatbot [“Ava”](https://venturebeat.com/2018/05/18/how-autodesks-assistant-ava-attempts-to-avoid-uncanny-valley/), that not only has conversations via a text-based messaging system, but also has a humanoid video interface and is purported to use the camera on one’s device to recognize basic emotional facial expressions (like anger, sadness, or happiness).  

![Photo credit to Soul Machines]({{ site.github.url }}/images/2018/06/Ava_SoulMachines-1528230607461.png)

In its early stages, Ava succeeded by combining the work of a cross-functional team at Autodesk with [IBM Watson technology](https://www.ibm.com/watson/how-to-build-a-chatbot/).  This allowed Autodesk to see immediate success with their chatbot, which (for specific use cases) can answer customers' questions in record time and tackle huge volumes of requests.  Autodesk still employs human customer service agents for more complicated inquiries, but using Ava has allowed them to change the way they do business (they suffered from very long wait times when they switched to a subscription-based business).

In addition to partnering with IBM Watson (and having a cross-functional team within Autodesk), by also partnering with [Soul Machines](https://www.soulmachines.com/), Autodesk was able to bring Ava to life, so to speak.  Soul Machines creates humanoid interfaces that they hope will, again, fundamentally change the way in which we interact with machines.  Their “interactive artificial humans” (or avatars), unlike early chatbots, are based on a series of neural networks and more complicated infrastructure that they claim to be the world’s [“first virtual nervous system.”](https://www.soulmachines.com/news/2018/4/30/blog-were-humanizing-artificial-intelligence)  

Leaving the technical readiness of this or other human-machine interactive platforms aside for the moment, it’s clear that we will see more and more effort going into creating virtual humans that can accomplish narrow tasks very quickly.  What we’re also seeing is an evolution of the way in which we conceptualize and prefer to interact with machines.  

---

## CFFL Updates
