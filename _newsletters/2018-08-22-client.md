---
layout: newsletter
slug: 2018-08-22-client
---

TODO: write intro

---
## Distilling the Knowledge of a Neural Network
_by [Friederike](https://www.linkedin.com/in/friederikeschueuer/)

"Many insects have a larval form that is optimized for extracting energy and
nutrients from the environment and a completely different adult form that is
optimized for the very different requirements of traveling and reproduction,"
[says machine learning expert Geoffrey
Hinton](https://arxiv.org/abs/1503.02531). Yet in machine learning, we tend to use very similar models during
training and in production, despite the very different requirements of each stage.

During training, we want algorithms to learn an accurate and reliable mapping
from input to output data - for example, from images of larvae, butterflies,
cats, dogs, and hermit crabs, to image labels: ``larva``, ``butterfly``,
``cat``, ``dog``, ``hermit crab``. As part of this training, algorithms have to
learn to extract useful features from data, a complex task that that may
require a large, complex model with many parameters. However, these models are
tricky to deploy in production. Inference (the act of labeling a new data point)
is slow, and the model is large; it takes up space. 

[*Knowledge distillation*](https://arxiv.org/abs/1503.02531) helps transfer the
knowledge of a large, complex network into a smaller, less complex one; it
turns the larva into the butterfly model. Fast and small, the butterfly model
is ready for (re-)production.

One way to distill the knowledge of a neural network into a smaller one is to
use the large, complex model as a ``teacher model`` and the smaller model as a
`` student model`` (there are [other ways](https://arxiv.org/pdf/1710.09505.pdf)).
The teacher model takes input data and provides a probability distribution over
all possible outcomes (labels). Meanwhile, the student model learns to predict
this probability distribution, the output of the teacher model. This
probability distribution (across the full label space) encodes a rich
similarity structure in the output space; confusable outputs have similar
probability values. For our most recent prototype, *Newsie*, for example, we
built a (multi-task) model for new classification. The model struggled to learn
to distinguish between entertainment and lifestyle articles: for a given
article, the model returned comparable probability values for these two
categories (high, if the article was indeed an entertainment or lifestyle
article, and otherwise low). This tells us something about the data:
entertainment and lifestyle articles tend to cover overlapping content in
similar language.

A student model trained on the probability distribution of the teacher model
performs better than a student model trained on the prediction of the teacher
model (the most likely category) or a student model trained on the original
training data of the teacher model. The student model trained on the
probability distribution across the full label space benefits from this
rich encoding of similarity.

![]({{ site.github.url }}/images/2018/08/Screen_Shot_2018_08_16_at_1_00_37_PM-1534438951405.png)
##### A [recent paper](https://arxiv.org/abs/1805.05532) uses knowledge distillation and adversarial samples to more closely align the decision boundary of the student and teacher model.

Hinton recommends to increase the temperature of the
[softmax](https://en.wikipedia.org/wiki/Softmax_function), a function used for
multi-class classification to turn arbitrary real numbers into a probability
distribution during knowledge distillation. A higher temperature leads to a
smoother probability distribution. This is helpful in case of a very high
performing teacher model. A high-performing model will assign most of its
probability to one and only one label, thus not encoding much similarity in the
output space. A high softmax temperature reverses this effect. (Note that
during training, the temperature parameter of the softmax of both the teacher and
student models need to match; the student model needs to be able to mimick the
behavior of the teacher model.)

Knowledge distillation is a great way to prepare a high-performing prototype
model for production; it's also been used to [fend off adversarial
attacks](https://arxiv.org/pdf/1511.04508.pdf) and for [cross-modal
transfer](https://arxiv.org/pdf/1507.00448.pdf).

---

## Shioulin's piece

---

## CFFL Updates

* Shioulin will be speaking on [Semantic Recommendations](https://conferences.oreilly.com/strata/strata-ny/public/schedule/detail/69260) at the Strata Data Conference in NYC on September 12th, and Friederike will be [speaking at Strata](https://conferences.oreilly.com/strata/strata-ny/public/schedule/detail/69365) on September 12th as well.

* Hilary will be keynoting at Strata on Thursday, September 13th.

* Friederike will be speaking at the [Data Science Salon](https://www.eventbrite.com/e/data-science-salon-nyc-tickets-40072527007) on September 27th (also here in NYC).

* Shioulin will be speaking at [ODSC Europe](https://odsc.com/london) in London in mid-September.

As always - thank you for reading!  We welcome your thoughts, questions, and suggestions; please reach out to us anytime at cffl@cloudera.com.

All the best,

The Cloudera Fast Forward Labs Team
