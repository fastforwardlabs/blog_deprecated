---
slug: 2019-05-29-public
layout: newsletter
---

Hello!  In this edition of our newsletter, we're discussing low-code ML toolboxes, and open-ended text generation.  We've also put together a recommended reading list of papers and articles we've enjoyed.

Be sure to catch [our latest blogpost on meta-learning](https://blog.fastforwardlabs.com/2019/05/22/metalearners-learning-how-to-learn.html), and [stay tuned](https://twitter.com/FastForwardLabs) for news about our next report soon! 

## Rise of the Low-Code ML toolboxes

_by [Justin](https://twitter.com/JustinJDN)_

The Fast Forward Labs team has written previously about the rapid growth and adoption of ML tools in the [AutoML](https://blog.fastforwardlabs.com/2017/11/30/the-promise-of-automated-machine-learning-automl.html) family.  Specifically, we broke down AutoML into 4 categories:

* Citizen Data Science / ML
* Efficient Data Science / ML
* Learning to Learn
* Transfer Learning

Advancement has been especially rapid in tools designed to make Data Science/ML more efficient, and in learning to automate/optimize model architecture design.  While these frameworks and tools have continued to mature, their prominence has unveiled another set of challenges.  Even when using automation, building out useful, semi-custom deep learning models takes a lot of code!  Popular libraries like TensorFlow and Pytorch offer incredible power in that data scientists (who also happen to be experienced software developers) have the ability to tailor model architectures granularly to fit specific use cases.  However, all of that power comes at a cost, and that cost can include hundreds of lines of code--and all of the technical debt that comes with it.  Add in the need to programatically implement many iterations of experiments, and one could easily end up maintaining a higly complex codebase simply to train, test, and experiment with a single deep learning model.

![]({{ site.github.url }}/images/2019/05/markus_spiske_109588_unsplash-1556815976857.jpg)
##### Photo by [Markus Spiske](https://unsplash.com/photos/xekxE_VR0Ec?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/code?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

To address this challenge, a new genre of ML capabilities has surfaced, pioneered by what we like to call 'Low-Code ML Toolboxes.' Projects like the Allen Institute's [AllenNLP](https://allennlp.org/tutorials), [fast.ai](https://www.fast.ai/) and Uber's [Ludwig] (https://uber.github.io/ludwig/) seek to abstract much of the programming complexity inherent to building deep learning models, while preserving the above-mentioned power of libraries such as Pytorch and TensorFlow.  These toolboxes are not limited to AutoML applications. As a result, they address codebase management challenges for many types of ML projects. 

These projects advertise themselves as a way to make deep learning much easier to accomplish and more accessible to the masses, and while this is technically true, it's important to point out that in this case we aren't talking about GUI-based approaches to ML/DL such as [Lobe](https://lobe.ai/), [KNIME](https://www.knime.com/) or even building lambda function-based models.  Instead, tools in this category seek to holistically reduce the programming load of data scientists by providing higher level text-based interface with which to specify a model's configuration.  

Both Ludwig and AllenNLP leverage the JSON format as a way to allow for custom configuration of a model architecture/approach, while still enforcing a standard structure, which is needed in order to provide abstraction.  Ludwig offers YAML as the primary user interface, which is then used to generate JSON model specifications.  AllenNLP uses jsonnet for the same purpose.  Ludwig does also feature a programmatic [API](https://uber.github.io/ludwig/api/), and many of AllenNLP's core capabilities can easily be integrated/extended to existing software projects.

Fast.ai takes a different approach, relying heavily still on it's users to develop models directly in Python.  However, through both the library's built in functions, as well as the project's well documented DS practices, management of a the codebase supporting a model is much simpler.

These projects are also showing high levels of adoption with the older AllenNLP [Github](https://github.com/allenai/allennlp) boasting over 100 contributors and 6,000 stars.  Ludwig, though only recently released, has nearly 4,500 stars at the time of this article and has strong support within Uber's extended AI community.  Because fast.ai is also paired with a human learning course, it also boasts a large community (over 13,000 stars and hundreds of contributers).

### Why low-code?

Increasing Data Scientist productivity is the primary benefit of low-code ML tools, but not the only one.  In addition to making it faster to experiment, these tools also seek to provide a repeatable and structured way to capture experiment results as well.  Both toolchains automatically log the details of each training run into a pre-specified directory/file hierarchy.  Once one is comfortable with this structure it's easy to pinpoint key moments in the experimentation process for further analysis or configuration.

In addition, since these low-code toolboxes are essentially built on top of well-maintained deep learning libraries (PyTorch and Tensorflow), it's easy to take advantage of other adjacent capabilities like [TensorBoard](https://github.com/tensorflow/tensorboard) to visualize/inspect models. 

### Possible Pitfalls

As discussed above, the developers of low-code ML tools make a lot of assumptions about how these tools will be used.  These assumptions are wide ranging, due to the level of abstraction provided.  One of the most important assumptions concerns how input data will be structured and preprocessed.  For example, Ludwig's standard toolchain expects data to be formatted into CSV, and currently only supports a limited number of datatypes and preprocessing functions.  While it is of course possible to extend the supported datatypes and preprocessing steps, you will need to write some code to do so.  Users who lack this skillset or become complacent during the experiment design process might run into trouble here.  

A primary component of many modern deep learning approaches is transfer learning (TL).  The benefits of this technique are plentiful and [well-documented](https://blog.fastforwardlabs.com/2018/08/29/breakthroughs-in-transfer-learning-for-nlp.html).  However, there is an inherent tradeoff to employing TL: it's sometimes impossible to know exactly on what and how someone else's model was trained, and thus very difficult to be sure if that model (or any derivative models) are fair, without inspection. Though the lack of automatic in-depth fairness analysis is not unique to the low-code toolboxes we are exploring, it's worth noting that just because experimentation and training processes are easier, one shouldn't assume the outputs are fair.

### Parting thoughts

There are *still* no tools which replace a solid conceptual foundation in ML and software development. However, for experienced practitioners, low-code toolboxes can help make the data science process much easier and faster. 

---

## Open-ended Text Generation
*by [Shioulin](https://twitter.com/shioulin_sam)*

The goal in open-ended text generation is to create a coherent portion of text that is
a continuation from the given context. For example, given a couple of sentences,
this capability makes it possible for machines to self-write a coherent
story. One can imagine using such a system for AI-assisted writing, but of
course it can also be repurposed to generate misleading (fake) news
articles. 

Ovid's Unicorn, written by [OpenAI's
GPT-2](https://openai.com/blog/better-language-models/), offers a glimpse of the
state-of-the art. Because it can generate astonishingly human-like passages, the
full GPT-2 model was not released initially (in Feb 2019) due to ethical
concerns. This decision resulted in a lively debate within the machine learning
community. (OpenAI has since decided (in May 2019) to use two mechanisms for
responsibly publishing GPT-2: staged release and partnership-based sharing.)

### How text generation works

To generate text, we typically use a language model along with a decoder. The
language model can be an LSTM, or something based on [the Transformer
architecture](https://arxiv.org/abs/1706.03762), such as the GPT model. The
language model outputs the likelihood of each word in the vocabulary being the
_next word_ in the sequence. Ideally, the decoder then picks the _best sequence
of words_ that leads to the highest probability (likelihood) based on this
information. To do this, one has to search through all the possible sequences of
words - this computation is not tractable. As such, two approaches are used in
practice: greedy search and beam search.

In _greedy search_, the decoder picks the word that has the highest likelihood
of being the next word in the sequence. It only looks at the next word, and in
doing so, is only exploring one path to building a sequence of words.

A better approach is _beam search_. Rather than exploring a single path, beam
search keeps track of multiple paths. While beam search is effective for
non-open-ended generation tasks such as machine translation, data-to-text
generation, and summarization, it does not work well for open-ended text
generation.

### Why doesn't beam search work for open-ended text generation?

Using beam search as a decoder for open-ended generation results in text that is
strangely bland and repetitive. This is not because of "search error, where beam
search failed to find higher quality sentences to which the model assigns higher
probability than to the decoded ones." Rather, the [fundamental problem is the
maximum likelihood decoding objective](https://arxiv.org/abs/1904.09751).

![Example of degenerate text using beam search. [Credit](https://arxiv.org/abs/1904.09751)]({{ site.github.url }}/images/2019/05/Screen_Shot_2019_05_08_at_3_06_29_PM-1557342465617.png)
##### Example of degenerate text using beam search. ([credit](https://arxiv.org/abs/1904.09751))

It turns out likelihood maximization approaches such as beam search tend to
produce sentences that loop repetitively. Further, the probability of forming a
loop ("I don't know, I don't know, I don't know") increases with a longer loop -
once looping starts, it is difficult to get out of it. In addition, probability
distribution of human-generated text turns out to be very different from
machine-generated text. When using a maximum likelihood framework, the
machine-generated text is composed of tokens that are highly probable, but
human-generated text exhibits much richness and variance.

![Human text is rich and surprising. [credit](https://arxiv.org/abs/1904.09751)]({{ site.github.url }}/images/2019/05/Screen_Shot_2019_05_08_at_3_06_36_PM-1557342561886.png)
##### Human text is rich and surprising. ([credit](https://arxiv.org/abs/1904.09751))
### Randomize!

Recently two approaches based on the idea of randomization have been shown to
work much better for open-ended generation. In [top-k
sampling](https://arxiv.org/abs/1805.04833), the decoder randomly samples from
the top-k most likely next words. This is the approach used to generate Ovid's
Unicorn. Another approach is to ["select the highest probability tokens whose
cumulative probability mass exceeds a pre-chosen threshold"](https://arxiv.org/abs/1904.09751). In other words, instead of selecting k
tokens, we select n tokens where the summation of the probability from all n
tokens exceed a certain threshold, p. This results in a different number of
possible next words (vs _k_ fixed candidates) each time, and can be particularly
effective when we have a large number of words with almost equal
likelihoods. Using top-5, we would have just picked 5. The remaining (10 for
example) will have been left out, even though these words have similar
likelihood when compared to the top 5.

We are excited about the technical advances in open-ended text generation, but are
cautiously optimistic for these advances to be put to good use for safe and
ethical machine learning.

---

## Recommended Reading

#### [Unsupervised Data Augmentation](https://arxiv.org/abs/1904.12848)

_I like this paper because much of the exciting and impactful work in machine learning in the last couple of years involves doing more with less data. This discusses back translation, which is gaining a lot of steam, and the area of data augmentation for text and unsupervised methods is relatively uncharted. Also, it shows that it can be combined and complementary to transfer learning, which weâ€™re already very excited about. In particular, you can get state-of-the-art results for sentiment detection using just 20 examples! Remarkable._ - [Seth](https://twitter.com/shendrickson16)

#### [Reinforcement Learning, Fast and Slow](http://bit.ly/2HcB4Ct)

_I like this paper because it highlights how borrowing from human cognition helps evolve our thinking of reinforcement learning. It focuses on addressing the slowness of traditional reinforcement learning with faster learning._ - [Alice](https://twitter.com/AliceAlbrecht)

#### [Microsoft launches a new drag-and-drop machine learning tool](https://techcrunch.com/2019/05/02/microsoft-launches-a-drag-and-drop-machine-learning-tool-and-hosted-jupyter-notebooks/)

_Microsoft just released its own set of ML tools. One is a drag-and-drop autoML tool (look out, SAS), but there are  task-specific components like form data extraction, which are totally Microsoft's business-y jam._ - [Ryan](https://twitter.com/jqpubliq)

#### [A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/)

_This is a concise checklist of tips and tricks for debugging neural networks._ -[Mike](https://twitter.com/mikepqr)

--- 
Just for fun:

![]({{ site.github.url }}/images/editor_uploads/2019-05-09-155640-tasks_2x.png)
##### Source: [XKCD](https://xkcd.com/1425/) 
---

#### [Challenges of Real-World Reinforcement Learning](https://arxiv.org/abs/1904.12901)

_This paper lays out nicely why reinforcement learning is hard in real life, and precisely why we have yet to do a standalone report on it._ - [Shioulin](https://twitter.com/shioulin_sam)

#### [AI Ethics: Seven Traps](https://freedom-to-tinker.com/2019/03/25/ai-ethics-seven-traps/)

_This article looks at the recent media and big tech attention to AI ethics through the critical lens of seven traps of thought that many commenters fall into. It claims (correctly, I think) that having a handful of rules or principles around AI ethics is insufficient to ensure ethical use of AI. In particular, that being ethical is an **activity**, not a **state**. I liked it because it goes beyond superficial and oft-repeated proclamations that AI ethics is important, and highlights why ensuring ethical use of AI is hard work._ - [Chris](https://twitter.com/_cjwallace)

#### [Parametric Press Spring 2019 - Issue 01: Science and Society](https://parametric.press/issue-01/)

_This is the first issue of Parametric Press, a digital magazine where each article is an interactive explainer - featuring articles on JPEG compression, bias in machine learning, and particle physics. It makes me happy that people are exploring the power of interaction as a tool for understanding._ - [Grant](https://twitter.com/GrantCuster)

#### [Google's distributed computing for dummies trains ResNet-50 in under half an hour](https://www.zdnet.com/article/googles-distributed-computing-for-dummies-trains-restnet-50-in-half-an-hour/)

_This article explains the work of several DeepMind researchers who thought distributed parallel ML computing has been way too hard for way to long and decided to do something about it.  _ - [Justin](https://twitter.com/JustinJDN)

#### [MixMatch: A Holistic Approach to Semi-Supervised Learning - PDF](https://arxiv.org/pdf/1905.02249.pdf)

_Semi-supervised techniques can be used to alleviate the need for large labeled datasets by leveraging the unlabeled data. This paper is interesting to me because it introduces a new semi-supervised algorithm - MixMatch that claims to achieve a better accuracy-privacy tradeoff for differential privacy. Think of medical use-cases where the labels may contain sensitive information and may be considered private._ - [Nisha](https://twitter.com/NishaMuktewar)

---

We hope you've enjoyed the content in this newsletter, and [welcome your feedback](mailto:cffl@cloudera.com).   Until next month!


All the best,

The Cloudera Fast Forward Labs Team