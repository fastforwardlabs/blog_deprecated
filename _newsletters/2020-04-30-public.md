---
slug: 2020-04-30-public
layout: newsletter
---

Hello! In this month's edition of our newsletter, we share some thoughts on Enterprise Grade ML, a list of articles and papers we've enjoyed reading, and announcements about our new research efforts. Enjoy!

---

## Enterprise Grade ML
*by [Shioulin](https://twitter.com/shioulin_sam)*

At Cloudera Fast Forward, one of the mechanisms we use to tightly couple
machine learning research with application is through [application development
projects](https://www.cloudera.com/about/services-and-support/fast-forward-labs.html) for both internal and external clients. The problems we tackle in these
projects are wide ranging and cut across various industries; the end goal is a
production system that translates data into business impact.

### What is Enterprise Grade Machine Learning?

Enterprise grade ML, a term mentioned in [a paper put forth by
Microsoft](https://arxiv.org/abs/1909.00084), refers to ML applications where
there is a high level of scrutiny for data handling, model fairness, user
privacy, and debuggability. While toy problems that data scientists solve on
laptops using a csv dataset could be intellectually challenging, they are not
enterprise grade machine learning problems.

### The current state of Enterprise Grade ML

In many of our projects, the most difficult portion is understanding the
business problem and defining a mathematical version that can be solved with the
data that is available. Sometimes this mathematical version is not what the
business stakeholders imagined it to be - this version might only partially
solve the original business problem due to data realities. Very often, the
business problem is broken down into smaller subproblems. The output of these
subproblems then feed into a thin layer of business logic/rules to arrive at a
final model output.

Once the problem is clearly defined, and data is flowing properly into the
modeling environment, building a model is rather straightforward. When model
building becomes convoluted, it can be taken as an indicator of an incorrect
problem formulation. There are various ways to approach model building (feature
creation, model selection, experimentation) ranging from fully custom approaches
to highly automated processes. We are partial to the old-school
Python-leveraging-packages approach but can envision the usefulness of AutoML if
a data scientist has strong intuition about the business problem and solid
understanding of the dataset.

In deployment (via containers or spark applications, for example), governance
becomes paramount, especially in regulated environments. Data lineage, data
versioning, model versioning, model explainability, model monitoring are all
front and center.

Today, we very often need to stitch together ad hoc tools to accomplish all the
above. What does the future look like?  [A recent paper](https://arxiv.org/abs/1909.00084) outlines a 10-year
prediction for enterprise-grade ML. Along the lines of [Software
2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35), the authors view
ML models as software derived from data. Most of us in the ML space would agree
with this view, and would also acknowledge that even though ML is software, in
today's practice we don't yet (always) adopt known best practices in software
development.

### Future state for Enterprise-Grade ML

The authors look to the future from three perspectives: i) model
development/training ii) model scoring and iii) model management/governance.

![Reference architecture for canonical data science lifecycle (Flock) [src](https://arxiv.org/abs/1909.00084)]({{site.github.url }}/images/2020/03/Screen_Shot_2020_03_27_at_4_17_39_PM-1585340376058.png)
##### Image Source: https://arxiv.org/abs/1909.00084

On model development/training, they believe training and development work will
move to the cloud, either private or public. This is consistent with our
observations.

On governance, the authors believe that all data, including deployed models (to
be thought of as derived data) and inferences made using them will need to be
robustly governed. This is something we attempt to do in our current projects -
capture code that trained the model, training data that went into it, model
inference results - albeit in an ad hoc/brittle way, depending on existing
architecture.

The most interesting viewpoint (to me) is their perspective on model
scoring. Because machine learning models are software artifacts derived from
data, the dual nature of software artifacts and derived data suggests that the
boundary between the data world and the modeling world will be fuzzy. The
authors believe that inference pipelines will be close to data, and inference on
data stored in a database management system should be done as an extension of
the query runtime. In other words, models should be represented as first-class
data types in a database management system. To investigate this, they
"integrated ONNX Runtime (a performance-focused inference engine for ONNX)
within SQL server and developed an in-database cross-optimizer between SQL and
ML to enable optimizations across hybrid relational and ML expressions." Early
results indicate that in-database management system inference is very promising.

As ML adoption quickens within enterprises and ML drives many business
decisions, the attention will shift to effects of these models. To reach a state
where ML models are defensible (privacy, security, interpretability, speed)
without much technical debt, the DB community and the ML community will both
shape the future of these ML end-to-end pipelines.

---

## Recommended Reading

#### [The impossibility of low-rank representations for triangle-rich complex networks](https://arxiv.org/abs/2003.12635) 

An esoteric title for the layperson, but the results of this paper have heavy implications for the users of graph embeddings. The authors prove that such embeddings fail to capture significant properties of their originating graphs. If embeddings lose key information, this can call into question the downstream results (e.g., machine learning models) that use those embeddings. Such implications are very relevant to my current work in biased knowledge graphs, where embeddings are used in many use cases. - *[Keita](https://twitter.com/keitabr)*

#### [The Basecamp Guide to Internal Communication](https://basecamp.com/guides/how-we-communicate) 

Everyone and their dog is giving out remote working tips at the moment. This is how Basecamp - a remote and asynchronous company - communicate. The guide is short and authoritative, and you should read it. - *[Chris](https://twitter.com/_cjwallace)*

#### [Invariant Risk Minimization](https://arxiv.org/abs/1907.02893) 

This is a beautiful paper intersecting causality and machine learning. I’ve spent quite some time with it while preparing our next research release (spoiler alert). For those with a machine learning background who are mystified by causal inference, this is a great starting point on the path, making the connection between causality, invariance, and generalization. - *[Chris](https://twitter.com/_cjwallace)*

#### [Data science at StitchFix](https://cultivating-algos.stitchfix.com/) 

An amazing post by StitchFix on how they approach data science within their organization through an interactive visualization! StitchFix’s take on organizational structure, roles and processes that are unique to them, yet applicable at other companies. And in many ways echoes Cloudera Fast Forward's thoughts in this space. - *[Nisha](https://twitter.com/NishaMuktewar)*

#### [A Visual Explanation of Transformer Models](http://jalammar.github.io/illustrated-transformer/) 

Transformer models have become the golden standard in sequence transduction tasks. This blog post visually depicts the inner workings of a Transformer architecture in a digestible level of detail and explains how this architecture lends itself to efficient, parallel computing. - *[Andrew](https://www.linkedin.com/in/andrew-r-reed/)*

#### [A Step Towards Protecting Patients from Medication Errors](https://ai.googleblog.com/2020/04/a-step-towards-protecting-patients-from.html)
Medication errors happen more often than we’d like to think and its not always the fault of the prescribing doctor or nurse. Most medical systems only have very simple rules-based error alerts for flagging medication issues. In this article, researchers discuss how they are using more sophisticated ML approaches, which are starting to learn how and when a doctor might prescribe a certain medication. This is an important step towards recognizing abnormal prescriptions and potentially saving lives. - *[Melanie](https://www.linkedin.com/in/melanierbeck/)*

#### [Generalization without Systematicity: On the compositional Skills of Sequence-to-Sequence Recurrent Networks](https://arxiv.org/abs/1711.00350) 

When we learn the meaning of a new verb "bah," we can easily generate and understand new phrases such as "bah twice." This is not true for neural networks, as they don't quite have the ability to exploit algebraic compositionality. Lake et al construct a simple dataset to test this hypothesis on various RNNs in a controlled manner. The dataset maps commands in words (jump left) into action sequences (LTURN JUMP). The learner's goal is to translate commands into a sequence of actions. The authors find that RNNs can make successful zero-shot generalizations when the difference between training and test commands are small, but fail spectacularly when the link between training and testing data is dependent on the ability to extract systematic rules (as in the "bah" example above). - *[Shioulin](https://twitter.com/shioulin_sam)*

---

## Research Updates

### *Interpretability*
Towards the beginning of April, we hosted a webinar on interpretability entitled **Opening the ML Black Box: Deploying Interpretable Models to Business Users**. You can catch the replay [here](https://www.cloudera.com/about/events/webinars/opening-the-ml-black-box-deploying-interpretable-models-to-business-users.html?utm_medium=clouderan&utm_source=field&keyplay=ml&utm_campaign=FY21-Q1_CW_AMER_ML_Black_Box_2020-04-09&cid=7012H000001Oh5c)! 

We also re-released our previous research on [Interpretability](https://ff06-2020.fastforwardlabs.com/) (with a few updates) to the public.

![]({{ site.github.url }}/images/editor_uploads/2020-04-23-190214-Interpretability.jpg)

### *Causality for Machine Learning*

Machine learning allows us to detect subtle correlations in large data sets, and use those correlations to make accurate predictions. However, these subtle correlations are often spurious - they exist only in a particular dataset - and the resultant model performs poorly, or gives unexpected results in the real world. 

Reasoning based on spurious correlations is dangerous.  Business decisions should be based on things that are true, not things that are true only in a limited dataset. The trouble, of course, is identifying what is spurious and what is not. 

Join us on May 28th at 10:00am PT / 1:00pm ET for a webinar on **[Causality for Machine Learning](https://www.cloudera.com/about/events/webinars/causality-for-machine-learning.html?utm_medium=email&utm_source=newsletter-FastForwardLabs&keyplay=ODL&utm_campaign=FY21-Q2_CW_AMER_Causality_for_ML_2020-05-28&cid=7012H000001OmCQ)**. During the webinar, we’ll explain how combining causal inference with machine learning can help us address these problems. We'll cover:
* when you should think about causality and lessons to apply in  your data science practice

* the latest research at the intersection of machine learning and causality

* how causal thinking helps us write models that generalize to new circumstances, including an example of the causal approach applied to a computer vision problem

We’ll also discuss the ethical implications of causality.  We look forward to seeing you there!

### *NLP for Question Answering*

Typically, our applied research culminates in a series of comprehensive reports provided to our customers on a quarterly basis, along with a live webinar demonstrating the prototypes we build in conjunction with that research. But times they are a-changin’ and we’re experimenting with new formats for distributing our content! This time, instead of waiting until the prototype is finished and the report is polished, we thought it would be fun to invite you to join us *while we build*.

We've launched a blog to host this endeavor at [qa.fastforwardlabs.com](qa.fastforwardlabs.com).  Learn more [here](https://blog.cloudera.com/developing-nlp-for-automated-question-answering/), and [follow us on Twitter](https://twitter.com/FastForwardLabs) for updates on when new content is posted!

---

## Cloudera Machine Learning

### **[Enabling Production MLOps at Scale - a Technical Preview](https://www.cloudera.com/about/events/webinars/enabling-production-ml-at-scale.html?utm_medium=clouderan&utm_source=field&keyplay=MDL&utm_campaign=FY21-Q2_CW_AMER_ML_at_Scale_2020-05-06&cid=7012H000001OhHN)**

For enterprises, getting machine learning (ML) models to production and scale has been a significant challenge. Today, only an estimated 12% of ML models make it to production. To tackle this challenge, Cloudera has released Cloudera Machine Learning (CML) MLOps — a comprehensive and secure production ML platform, built on a 100% open-source standard and fully integrated with Cloudera Data Platform. CML breaks the walls to production and enables end-to-end ML workflows at scale.

Join this webinar on May 6th at 10:00am PT / 1:00pm ET to: 

* Learn how CML’s MLOps functionality eliminates the model ‘black box’ and drives secure, transparent ML workflows from data to experimentation to production at scale.

* Experience CML’s robust and flexible model monitoring service for both technical metrics (latency, throughput, etc.) and the mathematical/functional monitoring — including first-class prediction tracking, metric stores, and Python SDK.

* See how CML’s unique model cataloging and model lineage capabilities eliminate silos and lead to better, faster results.

You can register [here](https://www.cloudera.com/about/events/webinars/enabling-production-ml-at-scale.html?utm_medium=clouderan&utm_source=field&keyplay=MDL&utm_campaign=FY21-Q2_CW_AMER_ML_at_Scale_2020-05-06&cid=7012H000001OhHN).