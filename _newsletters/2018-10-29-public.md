---
slug: 2018-10-29-public
layout: newsletter
---

Hello!  In this month's edition of the Cloudera Fast Forward Labs newsletter, we discuss meta-learning, the de-centralized web, and [MIT Intelligence Quest](https://quest.mit.edu/), and share a few thoughts on some articles, podcasts, and videos.  We also have a bit of news:

1) We're hiring! Please refer your data nerd friends. We currently have open positions for research engineers in [Brooklyn](https://cloudera.wd5.myworkdayjobs.com/External_Career/job/USNew-YorkBrooklyn/Research-Engineer-at-Cloudera-Fast-Forward-Labs_180950) and [San Francisco](https://cloudera.wd5.myworkdayjobs.com/External_Career/job/USA--California--San-Francisco/Research-Engineer-at-Cloudera-Fast-Forward-Labs_181051).  (For additional open positions at Cloudera, please visit [cloudera.com/careers](https://www.cloudera.com/careers.html).)

2) Please join us on Wednesday, Nov. 7th for a webinar not to be missed with Hilary Mason, at 10:00am PT / 1:00pm ET: [Industrialize AI with Enterprise 
Scale Machine Learning](https://www.cloudera.com/more/events/webinars/industrialize_ai.html?src=FFL).

3) We're excited to announce that we will have a new report coming out next month, on Federated Learning.  [Mike Lee Williams](https://twitter.com/mikepqr?lang=en) will be hosting a webinar to introduce the report on Thursday, Nov. 15th: [Federated Learning: ML with Privacy on the Edge](https://www.cloudera.com/more/events/webinars/federated_learning.html?src=FFL), also at 10:00am PT /1:00pm ET.

---

## Learning to learn in a model-agnostic way

_by [Nisha](https://twitter.com/NishaMuktewar)_

As humans, we can quickly adapt our actions in new situations, be it recognizing objects from a few examples, or learning new skills and
applying them in a matter of just a few minutes. But when it comes to deep learning techniques, an 
understandably large amount of time and data is required. So the challenge is to help our deep models do the same thing we can - to learn and quickly 
adapt from only a few examples, and to continue to adapt as more data becomes available. This approach of learning to learn is 
called **meta-learning**, and being a hot topic, has seen a flurry of research papers using techniques like 
[matching networks](https://arxiv.org/abs/1606.04080), [memory-augmented networks](https://arxiv.org/abs/1605.06065), 
[sequence generative models](https://arxiv.org/abs/1603.05106), [fast reinforcement learning](https://arxiv.org/abs/1611.05763)
and many others. 

Meta-learning methods differ from many standard machine learning techniques, which involve training on a 
single task and testing on held-out examples from that task. These systems are trained by exposing them to a large number of 
tasks and are then tested in their ability to learn new tasks; an example of a task might be classifying a new image within 5 
possible classes, given one example of each class.

![]({{ site.github.url }}/images/2018/10/meta_learning-1538505489954.png)
##### A meta-learning set-up for few-shot image classification from a paper on [Optimization as a Model for Few-Shot Learning](https://openreview.net/forum?id=rJY0-Kcll)

During this process, the model is trained to learn tasks in the meta-training set. There are two optimizations at play – the 
learner, which learns new tasks, and the meta-learner, which trains the learner. 

One of the recent benchmark papers in this area is [MAML: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400). 
Like other meta-learning methods, MAML trains over a wide range of tasks. It trains for a representation that can be quickly 
adapted to a new task, via a few gradient steps. The meta-learner seeks to find an initialization that is not only useful for 
adapting to various problems, but also can be adapted quickly (in a small number of steps) and efficiently (using only a few 
examples). Suppose we are seeking to find a set of parameters θ that are highly adaptable. During the course of meta-learning (the bold line), MAML optimizes for a set of parameters such that when a gradient step is taken with respect to a particular task i (the gray lines), the parameters are close to the optimal parameters θ<sup>∗</sup><sub>i</sub> for task i.

![]({{ site.github.url }}/images/2018/10/MAML-1538505613205.png)
##### [(Image source)](https://arxiv.org/pdf/1703.03400.pdf)

This approach is quite simple and has some distinctive advantages:   
- It does not make any assumptions on the form of the model, in the sense that it can be applied to any learning problem and 
model trained with gradient descent procedure.
- It is **parameter efficient** - there are no additional parameters introduced for meta-learning and the learner’s strategy uses a known optimization process (gradient descent), rather than having to come up with one from scratch.
- And, unlike other approaches, it can be readily applied to classification, regression  and reinforcement learning tasks.

---

## The Decentralized Web

*by [Grant](https://twitter.com/GrantCuster)*

Last week, Sir Tim Berners-Lee [announced Solid](https://medium.com/@timberners_lee/one-small-step-for-the-web-87f92217d085), a project designed to give users more control over their data. Solid is one of a number of recent attempts to rethink how the web works. As part of an effort to get my head around the goals of these different approaches and, more concretely, what they actually do, I made some notes on what I see as the most interesting approaches.

![A screenshot of the Beaker browser website.]({{ site.github.url }}/images/editor_uploads/2018-10-02-191324-Screen_Shot_2018_10_01_at_3_04_36_PM.png)

##### [Beaker browser](https://beakerbrowser.com/) for the peer-to-peer web.

The approach I’ve looked at the most is [Beaker Browser](https://beakerbrowser.com/). With Beaker you can view and create peer-to-peer websites using the [Dat protocol](https://datprotocol.com/). I got interested in Beaker because I had seen some of the more experimental designer-devs I follow experimenting with it. It’s very easy to get running, and the interface feels immediately familiar (the browser is built on Chomium, the open-source project that underpins Google Chrome). I viewed some peer-to-peer sites and looked at the number of seeders for them — but I didn’t really know where to go beyond that.

I got a much better picture of the goals and capabilities of Beaker through this talk by [Tara Vancil](https://www.youtube.com/watch?v=rJ_WvfF3FN8), a core member of the Beaker team. Part of the talk is focused on [the web we lost](https://anildash.com/2012/12/13/the_web_we_lost/): the beginner-friendliness of decipherable view source, and places like Geocities (where anyone could make their own weird web pages). With Beaker, you can make your own website and immediately host it on the peer-to-peer web without having to worry about setting up your own server. This could make it a great fit for demonstrations and classroom settings. To have a peer-to-peer site that stays up even when your computer is shut down and your seeders have run out is a bit more complicated. I found Tom MacWright’s [“So you want to decentralize your website”](https://macwright.org/2017/07/20/decentralize-your-website.html) a useful and realistic look at the steps involved.

![]({{ site.github.url }}/images/editor_uploads/2018-10-02-191445-Screen_Shot_2018_10_01_at_3_04_07_PM.png)

##### Tom MacWright's post "So you want to decentralize your website" [web link](https://macwright.org/2017/07/20/decentralize-your-website.html) [dat link](dat://tmcw.hashbase.io/2017/07/20/decentralize-your-website.html)

One of the most interesting parts of Vancil’s talk comes at the end, where she talks about the possibility of a Twitter-like site where each user can fork and modify the appearance and interface at will. She also talks about each user storing their identity locally (through a JSON file) and thereby maintaining control of their data. That vision for control of your data (that services connect to) is also the promise of Berners-Lee’s [Solid](https://solid.inrupt.com/) project. Solid, however, is built on top of the web, rather than being a new protocol.

Beyond trying to understand just what everybody is up to, I find these projects really interesting for the implicit theories about why the web is like it is. For Beaker, they believe lowering barriers to entry will create a weirder, more interesting network. Solid seems more aimed at offering an alternative to the data-collection and advertising business models of social media. [Brave](https://brave.com/) is another attempt to address that business model — an experimental ad-blocking browser with a blockchain-based publisher rewards feature. There are a lot of different approaches and goals swirling around, which is both confusing and kind of fun. Let us know if there is an area related to the decentralized web you think we should be paying attention to.

A few last links:
- You can get a feel for the variety of interests involved by looking through the conference website for the [Decentralized Web Summit 2018](https://decentralizedweb.net/). 
- [IPFS](https://ipfs.io/) is an alternative peer-to-peer protocol.

---

## The quest continues: a look at a new initiative to explore human and machine intelligence

_by [Alice](https://twitter.com/AliceAlbrecht)_

The resurrection of neural networks as a technique has helped propel the field of machine learning to the forefront of commercial applications. Today’s most popular applications focus on finding patterns in data and exploiting those patterns for very narrow tasks. But what if we want more from machine learning? Instead of trying to contort the methods we have today to achieve marginal gains in generalizability, what if we took another angle altogether?

Earlier this year, MIT launched [MIT Intelligence Quest](https://quest.mit.edu/), a large multidisciplinary group of researchers and engineers with two branches, “The Core” and “The Bridge.” The Core seeks to advance our understanding of intelligence in both humans and machines (and hopes the work from each area can inform the other). The Bridge provides a clear path toward applicability for industry and other academic labs inside and outside of MIT’s campus. The research community involved in MIT Quest does not just develop new algorithms or build tools to implement those algorithms; the group also researches the social, cultural, and ethical implications of AI research.

Some projects already coming out of The Quest are “moonshot” ideas that have the potential to really change the world. One such “moonshot” is led by work coming out of [Josh Tenenbaum's lab](https://arxiv.org/abs/1604.00289), which hopes to build models that exhibit infant-like capabilities to learn, using things like “intuitive physics” and “intuitive psychology.” These models are built using bayesian programs that utilize one-shot learning before generalizing. Tenenbaum’s moonshot project is just one of many that are being worked on as part of The Quest.

![]({{ site.github.url }}/images/2018/10/mike_petrucci_607505_unsplash-1539792581534.jpg)
##### _Moonshot (pun intended) Photo by [Mike Petrucci](https://unsplash.com/photos/uIf6H1or1nE?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/moon?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)_

We're excited to see where this research leads and are pleased to see the announcement this week that MIT received an unprecedented $1 billion to create the [Stephen A. Schwarzman College of Computing](http://news.mit.edu/2018/mit-reshapes-itself-stephen-schwarzman-college-of-computing-1015). This new college will likely help fund many more AI moonshot projects to come!

---

## An Ecclectic Round-up of Things We Like/Love

* We love it when data science makes a positive difference. Put your skills to work for a better world at a hackathon with [USA for UNHCR](https://twitter.com/USAforUNHCR) and [DonorsChoose.org](https://twitter.com/DonorsChoose), hosted by [Airbnb](https://twitter.com/Airbnb)- and follow the hashtag: #HackABetterWorld.  [Register here.](https://bit.ly/2q8lE8E)
* [Deep Reinforcement Learning for De-Novo Drug Design](https://arxiv.org/abs/1711.10907) -- ML for drugs! We can now use machine learning, a combination of deep generative and predictive models with a dose of reinforcement learning, to generate novel but chemically feasible compounds that may provide relief for infections and other diseases that lacked good treatment until now; it's data-driven drug screening and development now at scale.
* [Organizing my kitchen with Airtable](https://taravancil.com/blog/organizing-my-kitchen-with-airtable/) –- How to use Airtable (a lightweight database-spreadsheet hybrid) to plan your cooking. [Airtable](https://airtable.com/) is a neat tool and this post shows how much you can do with relatively simple but cleverly applied queries.
* [New AI Strategy Mimics How Brains Learn to Smell](https://www.quantamagazine.org/new-ai-strategy-mimics-how-brains-learn-to-smell-20180918/) -- This article highlights how we may be down too narrow a path when we design machine leaning models.  Olfaction (as opposed to vision) may serve as an excellent human model for machine learning and eventually artificial intelligence.  Plus, there are insect cyborgs!
* [A Taco Truck On Every Corner... or Not?](https://a2civic.tech/blog/2018/09/30/a-taco-truck-on-every-corner-or-not) - a fun application of postgres and GIS to answer the question: where is it legal to locate a taco truck in Ann Arbor, Michigan?
* [Federated Learning for Firefox](https://florian.github.io/federated-learning-firefox/) - federated learning (distributed learning that preserves privacy and minimizes communication costs) is the subject of our next report. There's lots of academic research, but this is the first article that goes into any technical depth about its production use.
* [Building Machines That Learn and Think Like People](https://arxiv.org/abs/1604.00289) - this article comes out of Josh Tenenbaum's lab (referenced above) and looks at how we can think of machine learning in terms of "model building" which uses models for understanding the world (based on human development) instead of focusing on pattern recognition.
* [Puzzles, Problems, and Programs](https://thestrangeloop.com/2018/puzzles-problems-and-programs.html) – in this talk Chris Martens looks at how we form mental models to solve problems.
* [What Does it Take to Train Deep Learning Models On-Device?](https://petewarden.com/2018/10/04/what-does-it-take-to-train-deep-learning-models-on-device/) We're thinking a lot about training models on unusual hardware at the moment, thanks to our upcoming report, and Pete Warden's post came at the perfect time.
* [The DataCamp Podcast](https://www.datacamp.com/community/podcast/): [This episode](https://www.datacamp.com/community/podcast/project-jupyter-interactive-computing) features interviews with our former CFFL colleagues Friederike Schuur and Emanuel Moss, on multi-task learning (at ~24:40 and ~44:00), and a third segment on multi-task learning with Friederike appears in [last week's episode](https://www.datacamp.com/community/podcast/decision-intelligence-data-science) as well (~43:45).

---

## CFFL and Cloudera ML Team Speaking Updates

* Matt Brandwein will speaking on "A Roadmap to Open Data Science" at [Cloudera World Tokyo](http://clouderaworldtokyo.com/2018/sE-04.html) (Tokyo, Japan) on November 6th.

* Alice Albrecht will be speaking at [NYAI](https://www.nyai.co/) on November 27th.

* Hilary Mason will be speaking at the [Cloudera Government Forum](https://events.publicsectornetwork.co/events/cloudera-government-forum-2018/) in Canberra, Australia on Tuesday, December 4th, and at [The AI Summit](https://theaisummit.com/newyork/) in New York City on Thursday, December 6th.

* Tristan Zajonc & Tim Chen will be speaking at [KubeCon](https://kccna18.sched.com/event/GrW2) on Wednesday, Dec. 12th.

As always, thank you for reading!  We welcome your thoughts and feedback; please [reach out](mailto:cffl@cloudera.com) anytime.

All the best,

Cloudera Fast Forward Labs
