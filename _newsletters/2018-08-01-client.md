---
layout: newsletter
slug: 2018-08-01-client
---

(TODO: write intro)

---

## Tech Piece Here

---

## Ethical Regulations and The Practice of Ethical Practice

A number of recent events, around projects that use machine intelligence to support government surveillance and security operations, have us revisiting the question of how the machine intelligence community is addressing the ethical and regulatory challenges it is currently facing. To briefly enumerate: in recent weeks, Google has ended its involvement with [Project Maven](https://gizmodo.com/google-plans-not-to-renew-its-contract-for-project-mave-1826488620), and obliquely responded to criticisms of its initial involvement by releasing a broader statement of [principles](https://www.blog.google/technology/ai/ai-principles/). A facial recognition system being trialed in London was found to have a [98% error rate](https://www.theverge.com/2018/7/5/17535814/uk-face-recognition-police-london-accuracy-completely-comfortable), apparently well within the comfort zone of the police chief there. Facial recognition systems are making [inroads](https://www.axios.com/facial-recognition-debate-coming-to-schools-nationwide-28d0ae08-567f-4c92-95e0-8cbc5a2329ec.html) to US school systems, raising privacy concerns across the board.  [Drones](https://www.theverge.com/2018/6/6/17433482/ai-automated-surveillance-drones-spot-violent-behavior-crowds) that purport to be able to detect violence amidst a crowd of people are now being deployed. And, Microsoft has responded to outcries about contracts with Immigration and Customs Enforcement (ICE) by denying its involvement in the massively controversial child separations occurring on the southern border of the US and releasing [a lengthy call](https://blogs.microsoft.com/on-the-issues/2018/07/13/facial-recognition-technology-the-need-for-public-regulation-and-corporate-responsibility/) for government regulation of facial recognition technologies, in addition to greater corporate responsibility.    

Microsoft's call for government regulation is a bit of an anomaly; companies rarely call for greater regulation of their industries, even if some eventually come to benefit (for example, from the kinds of broader boosts that the FAA has provided the aviation industry or that the NTSB has brought the automotive industry). Microsoft, in their call, is asserting that a lack of clear regulations makes it difficult to align working with the government to a corporate ethical stance if the government isn't clear about its own ethical stance. The line between what is legal and what is ethical can get murky in the absence of meaningful regulations. Their call raises excellent questions for government to answer, including "Should law enforcement use of facial recognition be subject to human oversight and controls, including restrictions on the use of unaided facial recognition technology as evidence of an individualâ€™s guilt or innocence of a crime?" and "Should we create processes that afford legal rights to individuals who believe they have been misidentified by a facial recognition system?". Microsoft recommends a bi-partisan commission to address these questions, with input from industry and academia. 

We think there are some uncertainties that regulation could be helpful in resolving, providing clarity, and incentivizing good behavior. As Hilary Mason (alongside DJ Patil and Mike Loukides) writes in a recent O'Reilly [post](https://www.oreilly.com/ideas/doing-good-data-science), "to put ethical principles into place, we need space to be ethical." Part of this may mean a regulatory space to practice ethics, but in the absence of that, there are other spaces to practice ethics: certainly at conferences and in training curricula, but also in our daily work. One way to turn our work into a space for ethical practices is to get into the habit of asking questions about the things we build. For classifiers, we might ask: 
 - What kind of drop in accuracy can we anticipate over real-world scenarios?
 - How will this product affect the public?
 - What are the consequences of any false positives our system may return to a user?
 - What type of legal status might our classifier have as evidence in a criminal or civil proceeding?
 
No list of such questions is exhaustive, and part of an ethical practice is to carefully think through what questions we are asking about our own work. Furthermore, ethical practices are a set of habits. They literally take _practice_; they might be difficult at first and produce uncertain outcomes, but they will become stronger over time.  

---

## Recommended Reading - and Cloudera Now

We love to read! Here are a few of our more recent favorite finds:
* [Modeling User Journeys via Semantic Embeddings](https://codeascraft.com/2018/07/12/modeling-user-journey-via-semantic-embeddings/)
* [Design Patterns for Production NLP Systems](http://deliprao.com/archives/294)
* [Program Synthesis in 2017-18](https://alexpolozov.com/blog/program-synthesis-2018/)
* [Design Patterns for Production NLP Systems](http://deliprao.com/archives/294)

We'd also like to recommend [Cloudera Now](https://www.cloudera.com/more/events/cloudera-now.html) on August 2nd; with a half-day, packed agenda highlighting some of our best customer case-studies, data use-cases, and engaging industry speakers, this online conference has an impactful keynote lineup and breakout tracks for both technical and business audiences. Cloudera Now will focus on the "how," and the best practices to help guide organizations through their data-driven journey. Learn more and register [here](https://www.cloudera.com/more/events/cloudera-now.html?utm_medium=email&utm_source=organicsdr&utm_campaign=other&src=sdr&cid=70134000001T2ub&utm_content=Cloudera%20NOW_Organic_AMER_Webinar_2018-08-02).

---

## CFFL Updates

* Mike will be speaking on "Serverless for Data Scientists" at [Pybay](https://pybay.com/) in San Francisco, on August 19th. (Learn more about Mike's talk in [this interview](https://medium.com/pybay/meet-mike-lee-williams-serverless-and-its-relevance-for-data-scientists-ba5a6cd0862e).)

* Shioulin will be speaking on [Semantic Recommendations](https://conferences.oreilly.com/strata/strata-ny/public/schedule/detail/69260) at the Strata Data Conference on September 12th, and Friederike will be [speaking at Strata](https://conferences.oreilly.com/strata/strata-ny/public/schedule/detail/69365) on September 12th as well.

* Friederike will also be speaking at the [Data Science Salon](https://www.eventbrite.com/e/data-science-salon-nyc-tickets-40072527007) on September 27th here in NYC.

* Shioulin will be speaking at [ODSC Europe](https://odsc.com/london) in London in mid-September.

As always - thank you for reading!  We welcome your thoughts, questions, and suggestions; reach us anytime at cffl@cloudera.com.

All the best,
The Cloudera Fast Forward Labs Team
