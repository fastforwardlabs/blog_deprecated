---
slug: 2019-01-31-public
layout: newsletter
---

Hello, and welcome to the January edition of Cloudera Fast Forward Labs' monthly newsletter.  This month we cover ML and IoT in agriculture and medicine, neural ordinary differential equations, and share a sneak peek at some of design process behind the prototype for our next report.  Enjoy!

---

## Machine learning and IoT combine to make real-world impact
_by [Alice](https://twitter.com/AliceAlbrecht)_

Scientists and researchers are pairing up with domain experts in various areas to apply machine learning techniques to the types of data collected from sensors in ways we could only dream of a decade ago. The results of these collaborations will only become more prevalent, and this week we'll walk through two recent successful collaborations that highlight some of the promise of translating cutting-edge machine learning research into applicable ideas that could fuel consumer products that may help solve some of the worlds hardest problems.

First, a recent challenge won by Microsoft research team [Sonoma](https://www.microsoft.com/en-us/research/project/sonoma/), which aims to develop autonomous indoor farms. The work done on this team combines agricultural domain expertise with new research in Bayesian, deep, and reinforcement learning. The challenge was the [autonomous greenhouse competition](http://www.autonomousgreenhouses.com/), set up by Wageningen University & Research and sponsored by Tencent. Sonoma won by training a combination of machine learning models on data collected from indoor farms.

![]({{ site.github.url }}/images/2019/01/greenhouse-1547573136097.jpeg)
##### _image source: [Autonomous Greenhouses](http://www.autonomousgreenhouses.com/)_

Advances in indoor farming, while potentially helping avoid a world food-shortage crisis, also provides fertile ground for research in reinforcement learning. Both indoor and outdoor controlled farming increasingly depends on both sensor and drone technology to measure and control the factors that affect plant growth. With massive amounts of data being collected and clear outcomes recorded (whether plants thrive or not), we anticipate that collaborations between machine learning and agricultural researchers will continue to propel each field forward.

Turning away from farming and instead to the difficulty in correctly diagnosing mental health disorders, [recent research](https://arxiv.org/abs/1811.08592) from Fei-Fei Li’s group illustrates how multi-modal facial expression and spoken language data can be combined to lead to improvements in depression screening. This work was presented this year at NeurIPS and illustrates how combining multiple widely-available types of data (which could be collected on smartphones) can enable practitioners to make faster and perhaps more accurate diagnoses. In a technical sense, this work is also novel in that it used sentence-, instead of word-level embeddings, and is able to glean good model performance with low-resolution facial image data (which allows for anonymizing participants’ data). This type of human-machine interaction holds particular promise because humans are more likely to disclose certain types of information to machines. 

We are excited to see how the IoT and machine learning, in combination with deep expertise in different fields will allow us to tackle problems that were previously too costly or even impossible.

---

## Neural Ordinary Differential Equations

_by [Chris](https://twitter.com/_cjwallace)_

### NeurIPS award papers

Last month, Montréal hosted the 2018 Neural Information Processing Systems (NeurIPS) . Each year, the conference makes a handful of “Best Paper” awards. The 2018 winners were:

* [Non-Delusional Q-Learning and Value-Iteration](https://papers.nips.cc/paper/8200-non-delusional-q-learning-and-value-iteration.pdf)
* [Optimal Algorithms for Non-Smooth Distributed Optimization in Networks](https://arxiv.org/pdf/1806.00291.pdf)
* [Nearly Tight Sample Complexity Bounds for Learning Mixtures of Gaussians via Sample Compression Schemes](https://papers.nips.cc/paper/7601-nearly-tight-sample-complexity-bounds-for-learning-mixtures-of-gaussians-via-sample-compression-schemes.pdf)
* [Neural Ordinary Differential Equations](https://arxiv.org/abs/1806.07366)

The Test of Time award winner was the worthy [The Tradeoffs of Large Scale Learning](https://leon.bottou.org/publications/pdf/nips-2007.pdf), which showed the value of using simple computations over lots of data instead of complex computations over less data for a fixed compute budget. Here we’ll dig into just one of the Best Paper award winners, but one we find very exciting.

## Neural Ordinary Differential Equations

Neural networks compose layer-wise transformations on hidden states. Feed forward networks compose these transformations sequentially: each layer takes the previous layer as input, and outputs a new hidden state. In residual networks (ResNets) - introduced in [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) - the transformations have a more specific form: each layer is the sum of the previous layer and a transformation on it. The intuition is that it is easier to learn a function for the difference between layers - a small correction - than model a new, improved output directly.

One of the problems that ResNets helped to solve was training very deep neural networks. In general, a deeper network is able to approximate more complex functions than an otherwise equivalent, shallower one. However, deep networks are notoriously difficult to train - training error can actually increase as more layers are added. By modelling the difference between layers, ResNets made it substantially easier to train very deep networks. If we take the idea of adding layers to its logical extreme and include infinitely many layers, each modelling an infinitesimally small change, it’s possible to express this transformation mathematically as an ordinary differential equation (ODE): an equation that describes a rate of change of one state as a function of a parameter. The innovation in [Neural Ordinary Differential Equations](https://arxiv.org/abs/1806.07366) is to take exactly that step, and replace the discrete hidden layers with a single function specified by an ODE; effectively giving the network _continuous depth_. ODEs are in general difficult to solve, but mature software exists to approximate them numerically, and the paper provides details of how the gradients necessary to train a continuous depth neural network are calculated through an ODE solver.

![]({{ site.github.url }}/images/2019/01/resnet_vs_odenet-1547848960089.png)
##### _The discrete steps of a Residual network with fixed evaluation points compared to a continuous depth ODE network which can be evaluated at any point in the transformation (circles are evaluation points in each). [Image credit](https://arxiv.org/abs/1806.07366)._

Since there are no layers to constrain it, the network must be evaluated at continuous timepoints. This facilitates adaptive computation, allowing one to trade off evaluation time with accuracy, by evaluating the continuous transformation at more or fewer points. It is possible to make this choice dynamically - for instance, one might train an ODE network using many evaluations for high accuracy, but evaluate it at only a few points when computation time must be minimized.

The paper shows that ODE networks have comparable performance to a ResNet on MNIST with only slightly more than a third of the parameters to train and constant memory requirements (whereas ResNet models’ memory requirements grow linearly with number of layers). The authors also demonstrate application to normalising flows - transformations of probability densities - showing that this continuous depth method can result in better approximations with fewer training iterations.

Perhaps the most exciting effect of replacing discrete layers with a continuous transformation is the ability to model continuous or irregularly sampled time series without discretising into fixed time steps; the authors suggest medical records and network traffic specifically. The paper shows the application to the toy problem of reconstructing a spiral from noisy measurements, achieving better results than a discrete recurrent neural network.

Neural ODEs are certainly in their infancy, but offer several novel tradeoffs, and we’ll be watching closely for new capabilities they facilitate. We’re especially eager to see continuous depth models used on continuous time series with real world data.

![]({{ site.github.url }}/images/2019/01/rnn_vs_odenet_spirals-1547848891840.png)
##### _ODE networks result in a much smoother approximation of two dimensional spirals than recurrent networks with discrete timesteps. [Image credit](https://arxiv.org/abs/1806.07366)._

---

## Recommended Reading

We love to read! Here are a few of our recent finds:

* [Firm Led by Google Veterans Uses A.I. to ‘Nudge’ Workers Toward Happiness](https://www.nytimes.com/2018/12/31/technology/human-resources-artificial-intelligence-humu.html) - a thoughtful look at an effort to use AI for good, with some insightful commentary on ethical considerations.
* [How Much of the Internet Is Fake? Turns Out, a Lot of It, Actually.](http://nymag.com/intelligencer/2018/12/how-much-of-the-internet-is-fake.html) - a great synthesis of a bunch of ideas and criticisms that are probably familiar to anyone working in adtech or otherwise trying to measure engagement on the web (be sure to read in combination with [this twitter thread](https://twitter.com/Chronotope/status/1078003966863200256).
* [The Greatest Trade Show North of Vegas (Pressing Lessons from NeurIPS 2018)](http://approximatelycorrect.com/2018/12/22/the-greatest-trade-show-north-of-vegas-pressing-lessons-neurips-2018/) - essential reading for anyone thinking of attending NeurIPS 2019!
* [The Yoda of Silicon Valley](https://www.nytimes.com/2018/12/17/science/donald-knuth-computers-algorithms-programming.html) - The New York Times profiles the legendary Don Knuth.
* [What Is the Role of Machine Learning in Databases?](https://rise.cs.berkeley.edu/blog/what-is-the-role-of-machine-learning-in-databases/) - a nice article on reinforcement learning to optimize query execution in databases.
* [A Full Hardware Guide to Deep Learning](http://timdettmers.com/2018/12/16/deep-learning-hardware-guide/) - if you'd like to own your deep learning hardware rather than rent it at $0.90/hour, this is the current situation. (Note: we can't promise your deep learning rig will appreciate in value like a San Francisco 1-bedroom, so it may make sense to continue renting!)
* [Kattis problem Pivot: Incrementally improving the performance of a python script, until nothing makes sense anymore](http://mycode.doesnot.run/2018/04/11/pivot/) - Fast Forward Labs alumnus Micha Gorelick wrote [a whole book](http://shop.oreilly.com/product/0636920028963.do) about ideas like these, but this short post is a fun read for Python programmers.

---

## Making an interactive UMAP visualization of the MNIST data set
by [Grant](https://twitter.com/grantcuster)

![A GIF of zooming into the MNIST visualization](http://feed.grantcuster.com/static/images/feed/umap_zoom-1547839236092.gif)

_[UMAP explorer: an interactive visualization of the MNIST data set](https://grantcuster.github.io/umap-explorer)_

We're in the middle of work on our next report, _Learning with Limited Labeled Data_, and the accompanying prototype. For the prototype's front-end we wanted to be able visualize and explore the embedding of a large image data set. Once you get into the tens of thousands of points, this can be a challenge to do in the browser. To determine whether what we wanted to do on the front-end was possible, I decided to make a demo focused on the MNIST hand-written digit data set. After some dead ends and a lot of Stack Overflow searching, it turns out it is possible, and I shared the result as [an interactive UMAP visualization of the MNIST data set](https://grantcuster.github.io/umap-explorer/).

## About UMAP

The UMAP algorithm is responsible for the clustering of the images in the demo. The coordinates for each data point in the visualization are from the [UMAP MNIST example notebook](https://github.com/lmcinnes/umap_paper_notebooks/blob/master/UMAP%20MNIST.ipynb). Check out [the UMAP guides and documentation](https://umap-learn.readthedocs.io/en/latest/) to learn more about how UMAP works.

## About the visualization

I'm sharing the demo as an example of how to render tens of thousands of images mapped to data points using the [three.js](https://threejs.org/) library. The code is available [on github](https://github.com/GrantCuster/umap-explorer) and can be adapted or used as a reference for doing similar visualizations with different datasets or algorithms.

_(Continue reading this article on [our blog](https://blog.fastforwardlabs.com/2019/01/29/making-an-interactive-umap-visualization-of-the-mnist-data-set.html))._

---

## CFFL News

* Hilary Mason will be speaking at the [Dataworks Summit](https://dataworkssummit.com/barcelona-2019/) in Barcelona, Spain on March 21st.
* Mike Lee Williams will be speaking on [Federated Learning](https://conferences.oreilly.com/strata/strata-ca/public/schedule/detail/72661) at the Strata Data Conference in San Francisco on March 27th.
* Mike will also be chairing the "deep learning in practice" track at [Qcon.ai](https://qcon.ai/) in San Francisco on April 16-17th.
* Stay tuned for additional CFFL speaking engagements this spring!

As always, thanks for reading!

All the best,

The Cloudera Fast Forward Labs Team
