---
slug: 2019-01-31-public
layout: newsletter
---

Hello!  (TODO: write intro)

---

## Machine learning and IoT combine to make real-world impact
_by [Alice](https://twitter.com/AliceAlbrecht)_

Scientists and researchers are pairing up with domain experts in various areas to apply machine learning techniques to the types of data collected from sensors in ways we could only dream of a decade ago. The results of these collaborations will only become more prevalent, and this week we'll walk through two recent successful collaborations that highlight some of the promise of translating cutting-edge machine learning research into applicable ideas that could fuel consumer products that may help solve some of the worlds hardest problems.

First, a recent challenge won by Microsoft research team [Sonoma](https://www.microsoft.com/en-us/research/project/sonoma/), which aims to develop autonomous indoor farms. The work done on this team combines agricultural domain expertise with new research in Bayesian, deep, and reinforcement learning. The challenge was the [autonomous greenhouse competition](http://www.autonomousgreenhouses.com/), set up by Wageningen University & Research and sponsored by Tencent. Sonoma won by training a combination of machine learning models on data collected from indoor farms.

![]({{ site.github.url }}/images/2019/01/greenhouse-1547573136097.jpeg)
##### _image source: [Autonomous Greenhouses](http://www.autonomousgreenhouses.com/)_

Advances in indoor farming, while potentially helping avoid a world food-shortage crisis, also provides fertile ground for research in reinforcement learning. Both indoor and outdoor controlled farming increasingly depends on both sensor and drone technology to measure and control the factors that affect plant growth. With massive amounts of data being collected and clear outcomes recorded (whether plants thrive or not), we anticipate that collaborations between machine learning and agricultural researchers will continue to propel each field forward.

Turning away from farming and instead to the difficulty in correctly diagnosing mental health disorders, [recent research](https://arxiv.org/abs/1811.08592) from Fei-Fei Li’s group illustrates how multi-modal facial expression and spoken language data can be combined to lead to improvements in depression screening. This work was presented this year at NeurIPS and illustrates how combining multiple widely-available types of data (which could be collected on smartphones) can enable practitioners to make faster and perhaps more accurate diagnoses. In a technical sense, this work is also novel in that it used sentence-, instead of word-level embeddings, and is able to glean good model performance with low-resolution facial image data (which allows for anonymizing participants’ data). This type of human-machine interaction holds particular promise because humans are more likely to disclose certain types of information to machines. 

We are excited to see how the IoT and machine learning, in combination with deep expertise in different fields will allow us to tackle problems that were previously too costly or even impossible.

---

## Model Server Madness

_by [Justin](https://twitter.com/JustinJDN)_

Model serving is getting easier, but you still have to know what you’re doing.  

Model serving is that thing that everybody wants to do but nobody actually has a plan for until it's an emergency: deploying ML models into a production environment and keeping them there so that they be utilized by apps, people, and other models. AutoML products may seem like a tailor-made solution to this challenge, and often do boast incredible benchmark performance numbers and easy to use APIs, but the need to address the [data product gap](https://www.slideshare.net/cloudera/demystifying-ml-ai-96567346) prevents these tools from becoming a practical, multi-use solution for the model serving requirement. 

Some companies, armed with lots of funding and a specific mandate to integrate AI/ML capabilities into the core of their business models, have spent years (and millions of dollars) developing fully bespoke end-to-end ML platforms - and we all benefit!  Not only do these modern model deployment and serving frameworks exist as reference architectures (such as Uber's Michelangelo, Facebook's FBLearner, or AirBnB's BigHead), but increasingly robust open source tools are now available to help automate the process of scoring real-world data by deployed ML models.  These platforms also serve as powerful data ingest systems, cross-domain feature stores, model evaluation tools, collaboration enablers, and workflow orchestrator/automators.  While these capabilities are certainly important to a robust enterprise ML/AI toolkit, they are not the focus of this article;  instead, it will explore the recent viability of **ML model servers**.   

Alex Vikati wrote about [*The Rise of the Model Servers*](https://medium.com/@vikati/the-rise-of-the-model-servers-9395522b6c58) last year, and things have only accelerated since then.  Put simply, an ML model server simplifies the tasks associated with deploying models and applying them for inference at scale.  Like more traditional application servers, these machines maintain a persistent architecture and typically serve results using robust APIs.  In her post, Vikati highlights five model server projects that graduated from the prototype to the robust phase recently.  Of that group: corporate projects like [TensorFlow Serving](https://www.tensorflow.org/serving/) and [MXnet Model Server](https://aws.amazon.com/blogs/machine-learning/introducing-model-server-for-apache-mxnet/) are especially attractive options for many enterprise teams seeking to productionize ML workflows.  

Other projects such as [Clipper](http://clipper.ai/) and [PredictionIO](https://predictionio.apache.org/) should also be mentioned in this conversation, but as they are less mature offerings and may appeal to a smaller audience, this article will not explore their capabilities in depth.

### Saying Hello to the World is easy when you have community

Getting started with TensorFlow Serving or MXNet Model Server only takes a couple lines of code and a few commands, and both server architectures provide immediate reproducibility and enhanced security, while allowing for easy version control and code isolation.  What's more, both architectures are well maintained by both the corporate dev teams and a robust user community focused on extending and optimizing their use.

 **Note:** just because a data science practitioner has the power to create an ML pipeline, doesn't mean that CI/CD practices should be sidestepped.  Also, scheduling and managing a few pipelines is quite different than hundreds or thousands of parallel jobs in production.

#### TensorFlow Serving

[This example](https://medium.com/tensorflow/serving-ml-quickly-with-tensorflow-serving-and-docker-7df7094aa008) from the Google Brain team quickly demonstrates the capability of TensorFlow Serving by applying a pre-trained ResNet to the task of image classification.  In this demo, the saved ResNet model is served to an image of a cat one hundred times using the Docker-based TensorFlow serving image.  The output provides the average server latency, as well as the prediction class for the image.

The relevant portion of the demo's python script is below: 

```console 
# Start the model Server

docker pull tensorflow/serving

docker run -p 8501:8501 --name tfserving_resnet \ 
--mount type=bind,source=/tmp/resnet,target=/models/resnet \
-e MODEL_NAME=resnet -t tensorflow/serving &
```

```python 

# Prerequisites include: installing and configuring Docker, downloading the TensorFlow serving image and then telling attaching the serving image to a pretrained ResNet model
# model with the name "resnet" and using the predict interface.

                                                                                                                                                                 
total_time = 0
num_requests = 100
for _ in xrange(num_requests):
    response = requests.post(SERVER_URL, data=predict_request)
response.raise_for_status()
total_time += response.elapsed.total_seconds()
prediction = response.json()['predictions'][0]

# Send few actual requests and time average latency.  

print('Prediction class: {}, avg latency: {} ms'.format(
prediction['classes'], (total_time*1000)/num_requests))

```

Though this example is running on a simple laptop configuration, it's not hard to see how this process could (and has been) successfully adopted to many production-level tasks. As mentioned above, the serving layer of an ML application's architecture is only one piece of the deployment puzzle. Two critical capabilities which are not covered in this demo, but would be required in even the simplest of production, are workflow orchestration and scheduling.  


#### MXNet Model Server

Getting started with MXNet's Model server is even simpler, assuming all prerequisites have been met.  To set up the listening function for a simple model server all that's needed is a single CLI command. 

```console

mxnet-model-server --start --models squeezenet=https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar
```

Of note: if your team is using python for ML development, you will need to be able to define and test models using either the Module or Gloun APIs available within the MXNet library.  There are specifications for converting PyTorch models to MXNet using the ONNX format, but many other libraries and model development environments are not supported or not fully supported.  [This quickstart guide](https://github.com/awslabs/mxnet-model-server#quick-start) walks a new user through server setup in a virtual environment, and serves up classification scores from a pre-trained squeezenet model for - you guessed it - images of cats, in JSON format.

![]({{ site.github.url }}/images/2019/01/mikhail_vasilyev_253977_unsplash-1547141586982.jpg)
##### Photo by [Mikhail Vasilyev](https://unsplash.com/photos/NodtnCsLdTE?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/)


```console
http://[server location]:8080/predictions/squeezenet -T [image location]/cat.jpg

{
    "class": "n02123045 tabby, tabby cat", 
    "probability": 0.5015981197357178
  }, 
  {
    "class": "n02123394 Persian cat", 
    "probability": 0.3994636833667755
  }, 
  {
    "class": "n02124075 Egyptian cat", 
    "probability": 0.09281889349222183
  }, 
  {
    "class": "n02123159 tiger cat", 
    "probability": 0.004449998494237661
  }, 
  {
    "class": "n02127052 lynx, catamount", 
    "probability": 0.0015094280242919922
  }

```


### Not so fast...

As exciting as these projects are, each of them come riddled with caveats, and actually implementing any of them in a real-world business context still requires significant investment along multiple dimensions:

1. **Integration Headaches**

	One of the biggest challenges lies in integration.  Many of these servers assume specific data ingest and output conventions are in place, which may not have been top of mind during experimentation and model development.

	Ultimately, the commoditized version of a model will not prove to be a truly novel competitive advantage widening IP.  Thus enterprises must invest in scalable yet flexible model service capabilities that can adapt to real-world models that actually impact business outcomes.  

	From a technical standpoint, this flexibility is usually represented by the amount of modeling algorithms supported and/or the performance that the architecture or platform can guarantee from the modeling capabilities that it supports.  Both TensorFlow Serving and MXNet Model server require very specific model "asset" types, which enable each tool to load a model into its particular serving architecture.  This capability comes with the requirement of ensuring that every model to be deployed meets a very specific convention (in these cases building models using either the TensforFlow API or MXNet library).  If your organization is unwilling or unable to adhere to these specifications, the ready-to-use server architectures won't work for you. 

2. **Training & Retraining Data Scientists (not to mention Data Engineers, ML Engineers, Analysts, etc..)**

	Another hurdle in the model serving process is ensuring that everyone involved in developing ML applications (from researchers through DevOps) is fluent in the same technology stack, tools, and environment necessary to utilize a model serving capability.  Though open source projects provide nearly infinite flexibility, the complexity of maintaining a common knowledge base can be daunting.  On the other hand, if an organization decides to go all-in on building out a bespoke end-to-end serving architecture - and invests in the processes, knowledge management, and technology infrastructure to maintain it - it must also commit to training new employees on how to use it.  

	Ultimately, a substantially different skillset may be required of your ML/Data Engineering teams that includes management of network ports, firewalls, server health, and more. 

	Uber shares in its engineering [blog](https://eng.uber.com/michelangelo/) that *"Uber ML education starts during an employee’s first week, during which we host special sessions for ML and Michelangelo boot camps for all technical hires"*.  Not every ML team has the bandwidth or political capital to design, deliver and maintain centralized platform education curriculum in this way.



3. **Knowing what model framework/technique and target production architecture to use**

	One of the best things about the practice of data science is also one of the worst things about it.  Rapid increases in computational power coupled with an explosion of commodity and semi-commodity tools (read: SciKit-learn, TensorFlow, PyTorch, R, etc...) now enable just about anyone to perform previously impossible machine learning tasks.  That same ease of use and flexibility often results in some pretty terrible code and impossible-to-recreate modeling environments.  As mentioned above, both server architectures explored in this post support only a limited number of ML libraries out of the box.  

	As a result, it's unreasonable to expect an IT or Engineering team to select the perfect scalable architecture for production without seriously constraining the experimentation process.

4. **Security and Access Control**

	Though both server architectures provide some inherent security through simple isolation of the ML workload, more robust security features like role-based access control, server hardening, and protection from outside attacks to the model architecture are not in scope for these projects.  To utilize these projects in a production environment out of the box, IT and Engineering teams are required to stitch together additional toolkits, or even develop net new features, in order to meet even simple security and compliance needs.


### So what is both possible *and* reasonable?

A third class of model serving projects are also receiving a lot of development attention: this time from companies seeking to simplify the entire AI/ML development to deployment experience using open source.  These products feature both the flexibility to support popular community-supported ML development libraries, while also adding in enterprise features such as fine-grained security, permissioning, and role-based access control.  

Products like Anaconda Enterprise, Domino Data Lab and IBM's Data Science Experience all provide some method of "serving" ML models - either as fully managed workflows or at least via RESTful APIs - that can be integrated into other applications. 

At Cloudera, [CDSW](https://www.cloudera.com/documentation/data-science-workbench/latest/topics/cdsw_overview.html) takes this approach, allowing users to deploy models as RESTful APIs to serve predictions through lightweight automated jobs - and schedule them, too.  One major benefit is that CDSW enables data scientists and engineers to operate on a common software/dependency stack and deploy ML workloads without the need for re-writes or extensive bespoke pipeline development.

Even though model servers and model serving architectures have made tremendous advances in viability recently and should certainly be considered when designing a production environment, it is clear that this area is not fully mature and is certainly not commoditized.  Data scientists, engineers, and leaders must work together to determine what is right for each organization.  

---

## Neural Ordinary Differential Equations

_by [Chris](https://twitter.com/_cjwallace)_

### NeurIPS award papers

Last month, Montréal hosted the 2018 Neural Information Processing Systems (NeurIPS) . Each year, the conference makes a handful of “Best Paper” awards. The 2018 winners were:

* [Non-Delusional Q-Learning and Value-Iteration](https://papers.nips.cc/paper/8200-non-delusional-q-learning-and-value-iteration.pdf)
* [Optimal Algorithms for Non-Smooth Distributed Optimization in Networks](https://arxiv.org/pdf/1806.00291.pdf)
* [Nearly Tight Sample Complexity Bounds for Learning Mixtures of Gaussians via Sample Compression Schemes](https://papers.nips.cc/paper/7601-nearly-tight-sample-complexity-bounds-for-learning-mixtures-of-gaussians-via-sample-compression-schemes.pdf)
* [Neural Ordinary Differential Equations](https://arxiv.org/abs/1806.07366)

The Test of Time award winner was the worthy [The Tradeoffs of Large Scale Learning](https://leon.bottou.org/publications/pdf/nips-2007.pdf), which showed the value of using simple computations over lots of data instead of complex computations over less data for a fixed compute budget. Here we’ll dig into just one of the Best Paper award winners, but one we find very exciting.

## Neural Ordinary Differential Equations

Neural networks compose layer-wise transformations on hidden states. Feed forward networks compose these transformations sequentially: each layer takes the previous layer as input, and outputs a new hidden state. In residual networks (ResNets) - introduced in [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) - the transformations have a more specific form: each layer is the sum of the previous layer and a transformation on it. The intuition is that it is easier to learn a function for the difference between layers - a small correction - than model a new, improved output directly.

One of the problems that ResNets helped to solve was training very deep neural networks. In general, a deeper network is able to approximate more complex functions than an otherwise equivalent, shallower one. However, deep networks are notoriously difficult to train - training error can actually increase as more layers are added. By modelling the difference between layers, ResNets made it substantially easier to train very deep networks. If we take the idea of adding layers to its logical extreme and include infinitely many layers, each modelling an infinitesimally small change, it’s possible to express this transformation mathematically as an ordinary differential equation (ODE): an equation that describes a rate of change of one state as a function of a parameter. The innovation in [Neural Ordinary Differential Equations](https://arxiv.org/abs/1806.07366) is to take exactly that step, and replace the discrete hidden layers with a single function specified by an ODE; effectively giving the network _continuous depth_. ODEs are in general difficult to solve, but mature software exists to approximate them numerically, and the paper provides details of how the gradients necessary to train a continuous depth neural network are calculated through an ODE solver.

![]({{ site.github.url }}/images/2019/01/resnet_vs_odenet-1547848960089.png)
##### _The discrete steps of a Residual network with fixed evaluation points compared to a continuous depth ODE network which can be evaluated at any point in the transformation (circles are evaluation points in each). [Image credit](https://arxiv.org/abs/1806.07366)._

Since there are no layers to constrain it, the network must be evaluated at continuous timepoints. This facilitates adaptive computation, allowing one to trade off evaluation time with accuracy, by evaluating the continuous transformation at more or fewer points. It is possible to make this choice dynamically - for instance, one might train an ODE network using many evaluations for high accuracy, but evaluate it at only a few points when computation time must be minimized.

The paper shows that ODE networks have comparable performance to a ResNet on MNIST with only slightly more than a third of the parameters to train and constant memory requirements (whereas ResNet models’ memory requirements grow linearly with number of layers). The authors also demonstrate application to normalising flows - transformations of probability densities - showing that this continuous depth method can result in better approximations with fewer training iterations.

Perhaps the most exciting effect of replacing discrete layers with a continuous transformation is the ability to model continuous or irregularly sampled time series without discretising into fixed time steps; the authors suggest medical records and network traffic specifically. The paper shows the application to the toy problem of reconstructing a spiral from noisy measurements, achieving better results than a discrete recurrent neural network.

Neural ODEs are certainly in their infancy, but offer several novel tradeoffs, and we’ll be watching closely for new capabilities they facilitate. We’re especially eager to see continuous depth models used on continuous time series with real world data.

![]({{ site.github.url }}/images/2019/01/rnn_vs_odenet_spirals-1547848891840.png)
##### _ODE networks result in a much smoother approximation of two dimensional spirals than recurrent networks with discrete timesteps. [Image credit](https://arxiv.org/abs/1806.07366)._

---

## Recommended Reading

We love to read! Here are a few of our recent finds:

* [Firm Led by Google Veterans Uses A.I. to ‘Nudge’ Workers Toward Happiness](https://www.nytimes.com/2018/12/31/technology/human-resources-artificial-intelligence-humu.html) - a thoughtful look at an effort to use AI for good, with some insightful commentary on ethical considerations.
* [How Much of the Internet Is Fake? Turns Out, a Lot of It, Actually.](http://nymag.com/intelligencer/2018/12/how-much-of-the-internet-is-fake.html) - a great synthesis of a bunch of ideas and criticisms that are probably familiar to anyone working in adtech or otherwise trying to measure engagement on the web (be sure to read in combination with [this twitter thread](https://twitter.com/Chronotope/status/1078003966863200256).
* [The Greatest Trade Show North of Vegas (Pressing Lessons from NeurIPS 2018)](http://approximatelycorrect.com/2018/12/22/the-greatest-trade-show-north-of-vegas-pressing-lessons-neurips-2018/) - essential reading for anyone thinking of attending NeurIPS 2019!
* [The Yoda of Silicon Valley](https://www.nytimes.com/2018/12/17/science/donald-knuth-computers-algorithms-programming.html) - The New York Times profiles the legendary Don Knuth.
* [What Is the Role of Machine Learning in Databases?](https://rise.cs.berkeley.edu/blog/what-is-the-role-of-machine-learning-in-databases/) - a nice article on reinforcement learning to optimize query execution in databases.
* [A Full Hardware Guide to Deep Learning](http://timdettmers.com/2018/12/16/deep-learning-hardware-guide/) - if you'd like to own your deep learning hardware rather than rent it at $0.90/hour, this is the current situation. (Note: we can't promise your deep learning rig will appreciate in value like a San Francisco 1-bedroom, so it may make sense to continue renting!)
* [Kattis problem Pivot: Incrementally improving the performance of a python script, until nothing makes sense anymore](http://mycode.doesnot.run/2018/04/11/pivot/) - Fast Forward Labs alumnus Micha Gorelick wrote [a whole book](http://shop.oreilly.com/product/0636920028963.do) about ideas like these, but this short post is a fun read for Python programmers.
* [Your Apps Know Where You Were Last Night, and They're Not Keeping It Secret](https://www.nytimes.com/interactive/2018/12/10/business/location-data-privacy-apps.html) and [I Gave a Bounty Hunter $300. Then He Located Our Phone](https://motherboard.vice.com/en_us/article/nepxbz/i-gave-a-bounty-hunter-300-dollars-located-phone-microbilt-zumigo-tmobile) - the data industry is increasingly a justified target of investigative journalists.

---

## CFFL News

* Hilary Mason will be speaking at the [Dataworks Summit](https://dataworkssummit.com/barcelona-2019/) in Barcelona, Spain on March 21st.
* Mike Lee Williams will be speaking on [Federated Learning](https://conferences.oreilly.com/strata/strata-ca/public/schedule/detail/72661) at the Strata Data Conference in San Francisco on March 27th.
* Stay tuned for additional CFFL speaking engagements this spring!

As always, thanks for reading!

All the best,

The Cloudera Fast Forward Labs Team