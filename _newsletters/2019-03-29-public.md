---
slug: 2019-03-29-public
layout: newsletter
---

Hello! In this month's newsletter, we highlight our new research on [Learning with Limited Labeled Data](https://blog.fastforwardlabs.com/2019/03/20/learning-with-limited-labeled-data.html), take a look at Google and OpenAI's activation atlas tool, and provide a brief recap of some exciting things that came from the recent TensorFlow Dev Summit.

---
## Machine Learning with Limited Labeled Data

Cloudera Fast Forward Labs’ latest research report and prototype (which will be released next week!) explores learning with limited labeled data. This capability relaxes the stringent labeled data requirement in supervised machine learning and opens up new product possibilities. It is industry invariant, addresses the labeling pain point and enables applications to be built faster and more efficiently. 

Join us on Wednesday, April 3rd at 10:00am PT / 1:00pm ET for a webinar introducing the report.  The webinar will be hosted by Shioulin Sam and Nisha Muktewar, with special guests Ines Montani (co-founder of Explosion AI) and Sanjay Krishnan (Assistant Professor of Computer Science at the University of Chicago).  You can register [here](https://www.cloudera.com/about/events/webinars/learning_with_limited_labeled_data.html?src=FFL) - and be sure to check out our latest blogpost on [Learning with Limited Labeled Data](https://blog.fastforwardlabs.com/2019/03/20/learning-with-limited-labeled-data.html), too.

---
## Do you see what I see? Visualizing higher order categories in neural networks

_by [Alice](https://twitter.com/AliceAlbrecht)_

Google and OpenAI have recently released a jointly developed tool to visualize the activation of neurons in an artificial neural network. They have coined the output of this tool “activation atlases.” (For reference, see: [Google AI Blog: Exploring Neural Networks with Activation Atlases](https://ai.googleblog.com/2019/03/exploring-neural-networks.html), and [Activation Atlas](https://distill.pub/2019/activation-atlas/).) 

Typical convolutional neural networks used in image classification are made up of different layers of artificial neurons that build on each other. This tool furthers previous work ([Feature Visualization](https://distill.pub/2017/feature-visualization/)) that overlaid activation grids on images to illustrate which features the model was picking up on at various layers of the network. 

Instead of examining a single image at a time, these activation atlases draw information from a randomly selected locations within 1 million images and average the attributes coming from each of those locations. These averaged attributes are then projected into a 2-dimensional space where similar attributes are located near each other. This illustrates which categories (rather than individual features) are represented. These are at a higher level (conceptually) than individual features. This work adds to an increasing body of work that allows deeper insight into how neural networks work, and makes them more interpretable.

![]({{ site.github.url }}/images/2019/03/Activation_atlases-1551983981470.png)
##### Image taken from the [OpenAI Blog](https://distill.pub/2019/activation-atlas/)

While this release allows much needed transparency into how neural networks represent information, it also raises an interesting question about how we think about artificial neural networks. It’s tempting to look at these activation atlases and see hope that these models are able to represent information in a way that’s similar to the way the human brain processes images (to be clear, the authors of this work do _not_ draw that conclusion). However, the similarities between artificial and human neural networks are slim, and the evolution from visualizing features to visualizing categories will necessarily have to end there; we won’t be able to infer higher-level information from these images this way (for example, whether something in an image is funny or surprising) given the way neural networks are currently structured.

We know that the human visual cortex encodes individual features and that information flows to other cortical areas that encode information about object categories, but the ways in which that information is transmitted is very different in human cortex than it is in silico.  Human brains have many different types of connections that aren’t accounted for in today’s artificial neural networks. (For instance, human brains contain lateral connections between neurons in the same layer, both local and long-range connections.)

As neural networks gain broader use, and we start to see human-understandable outputs of different layers of these networks, it’s tempting to believe that we’re getting closer to replicating something as complicated as human perception. We caution, however, that without a big shift in the way neural networks are designed, we’re unlikely to see progress in real human-like artificial intelligence until the complexity of the human brain is fully considered in our models. That said, this work is a great addition to the current body of work on making machine learning models more interpretable.

---
## Three exciting developments at TensorFlow Dev Summit 2019
*by [Chris](https://twitter.com/_cjwallace)*

The third annual TensorFlow Dev Summit was held. The entire first day of talks was live-streamed, and videos are available on the [TensorFlow YouTube channel](https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ). I stayed up late (from the UK) watching a few of the talks, and here’s an entirely idiosyncratic description of three things I find exciting. A broader [recap](https://medium.com/tensorflow/recap-of-the-2019-tensorflow-dev-summit-1b5ede42da8d) is provided by the TensorFlow team themselves.

### TensorFlow Federated

[TensorFlow Federated](https://www.tensorflow.org/federated/) is a library for federated learning. Given the title of our [last report](http://vision.cloudera.com/an-introduction-to-federated-learning/), you already know we think this is an exciting area. It was a group of Google researchers who coined the term “federated learning” with the release of the [Federated Averaging](https://arxiv.org/abs/1602.05629) algorithm for learning from decentralized data, so it makes sense that Federated Learning is getting the TensorFlow treatment.

The library includes both the high-level “Federated Learning” API designed for wrapping existing TensorFlow models, and a low-level “Federated Core” API, which is intended to the development of new federated learning algorithms.  The project is nascent, but particular attention has been paid to separating the various concerns of building a federated learning system. For instance, without some thought, it would easy to start entangling model operations and network communication. By providing high level abstractions, TensorFlow Federated allows experts in each area to contribute their respective knowledge, which could substantially lower the bar to entry for participating in federated learning research. The ability to wrap an existing Keras model is particularly appealing.

TensorFlow Federated currently includes only a simulated runtime (where all federated nodes actually live on the same, local, device), so it does not out-of-the-box “solve” federated learning. Eventually, other runtimes will be supported with the same API, meaning that the gap between researching novel federated approaches and deploying them to real federated networks is minimised.

### TensorFlow Probability

Likewise to federated learning, [probabilistic programming](https://blog.fastforwardlabs.com/2017/01/18/new-research-on-probabilistic-programming.html) is also something we’ve written about at Fast Forward Labs. Since our probabilistic programming report was released, the ecosystem has evolved. PyMC and Stan both continue to develop, but perhaps the most notable change has been the emergence of so-called “deep probabilistic programming” libraries. These libraries combine the ability of deep neural networks to learn complex functions with the probabilistic paradigm of computing with distributions. [Pyro.ai](http://pyro.ai/) runs atop PyTorch, and until recently, [Edward](http://edwardlib.org/) was the go-to library for TensorFlow.

[TF Probability](https://www.tensorflow.org/probability) takes a broader approach to probabilistic programming than Edward, introducing layers of abstraction into the “probprog” stack. At its base, it has complete interoperability with TensorFlow, which means all of TF’s linear algebra operations are available. On top of this is a set of “statistical building blocks” (their language): probability distributions and bijectors (composable transformations of random variables). There are also model building tools, including probabilistic programming language Edward2 - unsurprisingly, the successor to Edward - and a “probabilistic layers” component that can be used with high level APIs like Keras. Finally, there are a suite of probabilistic inference methods including Monte Carlo and Variational Inference.

The library has been evolving rapidly over the last year, but seems to be converging to a useful suite of tools. The TF Dev Summit [demo](https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb) of TensorFlow Probability included a simple and compelling walk through of building a regression model then including aleatoric (observation noise) and epistemic (model) uncertainty. It is encouraging to see probabilistic programming continue to mature and gain traction with existing software ecosystems.

### Swift for TensorFlow

Anyone at CFFL will tell you this particular newsletter author has a bit of a soft spot for probabilistic programming. Despite developments in TF Probability, of all the developments announced at the TF Dev Summit, I find the progress in [Swift for TensorFlow](https://www.tensorflow.org/swift) (which has moved into beta) the most promising.

Swift is an open source language from Apple, first designed to provide a better development experience for iOS and OSX (but now also supporting Linux, less a few niceties like automatic test discovery). Chris Lattner, who implemented much of the Swift language while at Apple, is now working on bringing TensorFlow to Swift. However, this is not a simple wrapper around the existing TensorFlow codebase, but rather a re-imagining of what tools for machine learning can be. Swift for TensorFlow integrates automatic differentiation into the Swift language itself, allowing easy definition of performant custom operations. Swift is fast, expressive and has an advanced type system. At CFFL, we love Python, and the Swift for TensorFlow team have also provided an almost native experience for interoperability with Python.

The watch words are “differentiable computing,” and we eagerly await more demo applications in this ecosystem. One advantage to Swift, being designed as a replacement for C family languages is that it is not necessary to wrap C libraries for performant numerical code. This means one can move up and down the numerical computing stack in the same language, which is also great for pedagogy. Speaking of pedagogy, Jeremy Howard of Fast.ai has [noticed](https://www.fast.ai/2019/03/06/fastai-swift/) Swift too, and at the TF Dev Summit, it was announced that the next iteration of the Fast.ai course will include a Swift component from Chris Lattner himself.

---

## Upcoming Events

* Hilary Mason will be speaking at the [Marketing Analytics and Data Science Conference](https://marketing.knect365.com/marketing-analytics-data-science/) in San Francisco, CA on April 10th.
* Mike Lee Williams will be chairing the "deep learning in practice" track at [Qcon.ai](https://qcon.ai/) in San Francisco on April 16-17th.
* Chris Wallace will be speaking on _[Federated learning: machine learning with privacy on the edge](https://conferences.oreilly.com/strata/strata-eu/public/schedule/detail/74327)_ on May 1st at the [Strata Data Conference](https://conferences.oreilly.com/strata/strata-eu) in London.
* Shioulin Sam will also be speaking at Strata in London on _[Learning with Limited Labeled Data](https://conferences.oreilly.com/strata/strata-eu/public/schedule/detail/74341)_ on May 2nd.

We'll also be at the Dataworks conference in Washington, D.C. on May 23rd! Here are the talks we'll be giving:
* Hilary Mason: _[Building an Enterprise AI Factory](https://dataworkssummit.com/washington-dc-2019/keynote/building-an-enterprise-ai-factory/)_
* Tristan Zajonc: _[Cloud-Native Machine Learning: Emerging Trends and the Road Ahead](https://dataworkssummit.com/washington-dc-2019/session/cloud-native-machine-learning-emerging-trends-and-the-road-ahead/)_
* Nisha Muktewar: _[Learning with Limited Labeled Data](https://dataworkssummit.com/washington-dc-2019/session/learning-with-limited-labeled-data-2/)_
* Alice Albrecht: _[A Framework for Developing a Winning Data Project Portfolio](https://dataworkssummit.com/washington-dc-2019/session/a-framework-for-developing-a-winning-data-project-portfolio-2/)_
* Justin Norman and Sagar Kewalramani: _[Machine Learning Model Deployment: Strategy to Implementation](https://dataworkssummit.com/washington-dc-2019/session/machine-learning-model-deployment-strategy-to-implementation-3/)_

If you're attending any of these conferences, please [let us know](mailto:cffl@cloudera.com) and stop by to say hello! 


All the best,

The Cloudera Fast Forward Labs Team