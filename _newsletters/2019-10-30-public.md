---
slug: 2019-10-30-public
layout: newsletter
---

Hello, and welcome to the October edition of the Cloudera Fast Forward monthly newsletter. This month we're talking about progress in computer vision technology and exciting applications of graph neural networks. We're also bringing back our recommended reading section, because - well, we *are* your nerd best friends. (Oh! which reminds us... pro-tip: if you're looking for a last-minute costume for Halloween [machine learning can (maybe) help](https://www.nytimes.com/interactive/2018/10/26/opinion/halloween-spooky-costumes-machine-learning-generator.html)!)

---

## Fuzzy People

*by [Chris](https://twitter.com/_cjwallace)*

While preparing for a recent edition of the Federated Learning talk I often give at conferences, I encountered [this tweet](https://twitter.com/EliotAndres/status/1175101115966398464), which includes a demonstration of real-time multi-person segmentation on a smartphone.

Some useful terminology here: 
* Object _detection_ typically refers to identifying and localising objects (such as people!) in an image, and surrounding them with a bounding box.
* Object _segmentation_ labels each pixel of the image with a class (for instance: "person," "car," "cat," ...).

Segmenting multiple people in an image is substantially harder than segmenting a single person, because identifing the parts of the image that belong to each person essentially requires modeling each person's pose. Without understanding human poses, how would our function-approximating neural network know that an arm around a shoulder belongs to person one, rather than person two?

This technology working on a mobile device in real-time is impressive.

There is good reason to be concerned about the malicious or misguided use of facial recognition technology to invade personal privacy. However, there are many conceivable applications for computer vision in public spaces which do not require incidental privacy violation - monitoring road traffic, for example.

A potential use of the raft of face-swapping apps recently launched is protecting the identity of people in the background of video or photos, while maintaining the realism of the image.

This naturally raises the question: what is private?

If you know me well, you can probably recognise me with an obfuscated face, based on clothes and surroundings. The overt pixellation in the mobile demo appealed to me. Because vision so viscerally connects to our senses, it strikes me as a fascinating arena in which to test theoretical measures of privacy.

I managed to find a few older papers covering this idea - though given it's import, it feels under-explored.

### When in doubt, play.

Thanks to the ready availability of pre-trained models, TensorFlow.js, Observable notebooks, and some free time at a conference, I could reasonably straightforwardly construct a person pixellator, which you can try for yourself here: [Fuzzy People](https://observablehq.com/@cjwallace/fuzzy-people).

It can take an input image, such as this:

![]({{ site.github.url }}/images/editor_uploads/2019-10-18-162850-bridge_not_fuzzy.png)
##### Brooklyn Bridge with pedestrians  (image courtesy of [unsplash.com](https://unsplash.com/photos/AM23EReEsdc))

And output (an attempt at) a more private version:

![]({{ site.github.url }}/images/editor_uploads/2019-10-18-162954-bridge_fuzzy.png)
##### Brooklyn Bridge with fuzzy pedestrians

Since the picture is really intended to be of the Brooklyn Bridge and Manhattan skyline, we've done the pedestrians a favour and hidden their identities.

Clearly, it doesn't work perfectly.

Some experimentation reveals it to work best when the people are in the foreground, clearly separated, there are only a few of them, and the picture was taken in reasonable lighting and weather conditions.

Nonetheless, I'm impressed by how well it sometimes does work, given that it is running some quite sophisticated models entirely inside a web browser.

The pixellation technique used is simple: for each pixel that the model identifies as a person (the model here is a combination of a bounding box with COCO-SSD, and single person segmentation with BodyPix), replace it with a randomly selected pixel from within an adjustable region. At low noise, where the region the random pixel is selected from is small, people in the images are still human identifiable. As noise is increased, people progressively become less person-like and more static. 

Finding a less intrusive - but still highly private - means of masking people from images is left as an exercise to the research community.

The app is extremely early stage work, but I think credit is due to the open source community for providing pre-trained models to enable the creation of something that would have seemed magic a decade ago in a day or so of hacking. Certainly, we are past the point where some elements of computer vision can be considered as commodity: simply import the "detect person" function.

_A side-note on the pace of change in this space_:

Alas, much of my work is wasted. About a week after I made the notebook work, a multi-person version of BodyPix was released! While I confess to feeling slightly stung by having sunk a few hours into pixel manipulation to combine a bounding box model with a single-person segmentation model that has ultimately proved unnecessary, I'm excited to try out the new model. It certainly brings home the feeling of rapid progress in computer vision technology.

---

## Exciting Applications of Graph Neural Networks

*by [Keita](https://twitter.com/keitabr)*

Graph Neural Networks (GNNs) are neural networks that take graphs as inputs. These models operate on the relational information in data to produce insights not possible in other neural network architectures and algorithms.

While there is much excitement in the deep learning community around GNNs, in industry circles, this is sometimes less so. So, I’ll review a few exciting applications empowered by GNNs.

### Overview of Graphs and GNNs

A graph (sometimes called a network) is a data structure that highlights the relationships between components in the data. It consists of nodes (or vertices) and edges (or links) that act as connections between the nodes. Such a data structure has an advantage when dealing with entities that have multiple relationships.

Graph data structures have been around for centuries and their modern use cases are wide. Well-known industry applications of graphs include the social networks of Facebook and LinkedIn, and street and road networks used in navigation apps such as Google Maps and Waze.

![]({{ site.github.url }}/images/editor_uploads/2019-10-25-173715-graph_basics.png)
##### A graph data structure ([image credit](mathinsight.org))

Graph Neural Networks are inspired by deep learning architectures, and strive to apply these to graph structures. Many of these architectures are direct analogues of familiar deep neural net counterparts. These include Graph Convolutional Networks, Graph Encoders and Decoders, Graph Attention Networks, and Graph LSTMs.

GNNs have been around for about 20 years, and interest in them has dramatically increased in the last 5 years. In this time, we’ve seen new architectures emerge, novel applications realized, and new platforms and libraries enter the scene.

Below, I highlight three novel uses of GNNs.

### Application 1 - Predict Side-Effects due to Drug Interactions
Every year in the United States, hundreds of thousands of seniors are hospitalized due to the negative side effects of one or more prescribed drugs. Meanwhile, the number of older people prescribed multiple drugs at a time is expanding. Given the proliferation of pharmaceuticals, it is not possible to experimentally test each combination of drugs for interaction effects. In practice, doctors rely on training, understanding a patient’s medical history, and studying literature about the drugs in use to gauge the risk of harmful side effects.

Classification and similarity algorithms have been applied to this problem before, producing interaction scores. These results have been limited for a few reasons.  The scores they produce are scalar values that highlight the risk of interaction without characterizing the nature of the interaction. These algorithms are limited to pairs of drugs.

By applying a type of GNN called a Graph Convolutional Network (GCN), a [team at Stanford](http://snap.stanford.edu/decagon/) has been able to produce a model that can predict specific drug-drug interaction effects due to the interaction of more than 2 drugs. This model, which outperforms previous methods in identifying such effects, can identify side effects that are not attributed to the individual input drugs.

![]({{ site.github.url }}/images/editor_uploads/2019-10-25-173752-drug_protein_effect_graph.png)
##### Example of input graph of drug and protein interactions, and side effect edges used to train the Stanford model ([image credit](snap.stanford.edu/decagon))

### Application 2 - Node Importance in Knowledge Graphs
The knowledge graphs produced by some enterprise companies are multifaceted, containing context and relationships across several types of entities and objects. Such graphs can contain billions of objects. Amazon is one such company, using knowledge and product graphs to capture the relationships between product data and the critical context that humans have but machines lack. Such graphs enable machines to excel at downstream applications like product recommendations and question answering.

However, at the scale of data that an enterprise uses, sifting through this massive amount of context can time-consuming and will impede graph-enabled applications.

To ameliorate this, [Amazon has developed](https://arxiv.org/abs/1905.08865) a GNN, called GENI (GNN for Estimating Node Importance), to distinguish the trivial facts and data from critical information contained in a knowledge graph. This algorithm was tested on knowledge graphs of movies, music, and general facts - but has wide ranging implications when applied to large scale graphs.

### Application 3 - Enhancing Computer Vision with Physical Intuition
Computer Vision has advanced rapidly with the help of deep learning - in areas of image classification, object detection, and pixel segmentation (among others). Machines can distinguish and identify objects in images and video. There is still much development needed for machines to have the visual intuition of a human. 

One type of human intuition is related to physics. If we see a ball bounce, we can reason about its trajectory. Even for more dynamic interactions among several objects, we can make reasonable predictions about what will happen without having a deep knowledge about the laws of motion or Newton’s three laws.

[Interactive Networks](https://papers.nips.cc/paper/7040-visual-interaction-networks-learning-a-physics-simulator-from-video.pdf) are now giving machines this same physical intuition. This results in models that can predict what will happen over an extended time, given a few frames of a video scene. An example from DeepMind combines a CNN that distinguishes objects in a scene with an Interactive Network, which reasons about the relationships between these objects. The results of these models have been posted in videos, which are overlaid on CIFAR images. These videos compare the projected trajectories of objects against those predicted by a physics simulator.

![]({{ site.github.url }}/images/editor_uploads/2019-10-25-173818-interactive_network.png)
##### Examples of trajectories done by a physics simulator (middle), compared with predicted trajectories over 40-60 video frames (right) ([image credit](https://deepmind.com/))

### Closing Thoughts
The applications discussed above highlight the functional variety of GNNs. In the first application, the GNN solution is used to predict graph edges. In the second, GNNs are used to score the importance of graph nodes. The third application uses GNNs predict the future states of a network.

These 3 applications only scratch the surface of the work being done around GNNs. The growth in this area is accelerating as people try to expand the usage of their existing graph-data. Researchers are also taking data that is in relational or document form, and reframing it in graph structures to take advantage of GNNs and other graph-analytical tools and methods.  Though the above examples use GNN architectures for specific purposes, the potential to apply their solutions to similar problems in different domains is exciting.

---

## Recommended Reading

As a research engineering team, we spend a lot of time reading articles and papers; here are a few of our recent favorites:

#### [Extreme Language Model Compression with Optimal Subwords and Shared Projections](https://arxiv.org/abs/1909.11687)

Pretrained language models such as BERT, ELMo, and GPT have achieved state of the art performance for a variety of language understanding tasks. However, the size of these models make them impractical for a number of scenarios, especially on mobile and edge devices. This paper introduces a new model distillation technique (more on model distillation [here]( https://arxiv.org/abs/1503.02531)) that enables a compressed version of BERT (from 420MB to 6.8MB, over 60x compression!!) with minimal loss of accuracy. These results will directly enable the use of such high accuracy models on end user and edge devices. - *[Victor](http://twitter.com/vykthur)*

#### [Data Shapley: Equitable Valuation of Data for Machine Learning, pdf](http://proceedings.mlr.press/v97/ghorbani19c/ghorbani19c.pdf)

As we think about shifting data ownership back to the generators of data and thus opening up the possiblity of compensating owners for their data, the ability to value a datapoint becomes necessary and crucial. This paper discusses one way to do so.   - *[Shioulin](http://twitter.com/shioulin_sam)*

#### [Doing enterprise financial data visualization after data journalism](https://medium.com/@tophtucker/doing-enterprise-financial-data-visualization-after-data-journalism-3c68861b7f4c)

Toph Tucker writes about his experience moving into financial data visualization. The article is wonderful in its concreteness. I especially liked the discussion about how power-users have different needs then first-time viewers. This is often a tension I have to deal with in the design of our prototypes. There's a lot of curiosity-driven empathy in Tucker's explanation of why tools that may not be aesthetically appealing at first glance are actually well-designed for their purpose. - *[Grant](http://twitter.com/grantcuster)*

#### [The Wavefunction Collapse Algorithm explained very clearly](https://robertheaton.com/2018/12/17/wavefunction-collapse-algorithm/)

The wave function collapse algorithm, used for creating varied but coherent tilemaps, looks like the sort of thing that requires a neural network -- but it doesn't. Robert Heaton lays out how it works, using a simplified version and a wedding party metaphor to communicate the core idea. The article is interesting for its content and as an example of trying to make technical content accessible (something we focus on as well). - *[Grant](http://twitter.com/grantcuster)*

#### [The State of Transfer Learning in NLP](https://www.kdnuggets.com/2019/09/state-transfer-learning-nlp.html)

This article is a summary of some of the very latest research in transfer learning for NLP. It includes back-references to the author's prior posts and presentations ,which are useful for getting up to speed on transfer learning and NLP, and then learning about the directions of cutting edge research. - [Ryan](https://www.linkedin.com/in/micallef/)

#### [Overton: A Data System for Monitoring and Improving Machine-Learned Products](https://arxiv.org/abs/1909.05372)

Just one example of a wave of papers giving insight into the infrastructure and processes surrounding machine learning products at large tech companies. The industrialization of machine learning is in its infancy, and I find experience reports for machine learning technologies deployed at scale useful in informing my thinking, even when it's about much smaller problems. Pushing system-level abstractions to large scales seems a good way to test them. - *[Chris](https://twitter.com/_cjwallace)*

---

## Upcoming Events

* If you're in the Bay Area, we'd love to invite you to be our guests for [Data Science Wrangle](https://events.attend.com/f/1383790393) in Palo Alto tonight at Cloudera's Headquarters!
* Victor Dibia will be speaking on *"Handtrack.js: Building Gesture Based Interactions in the Browser Using Tensorflow.js"* at the [TensorflowWorld Conference](https://conferences.oreilly.com/tensorflow/tf-ca/public/schedule/detail/77833) in Santa Clara, CA tomorrow.
* Victor will also be speaking on "ML in the Browser: Interactive Experiences with Tensorflow.js" at [QCon](https://qconsf.com/sf2019/track/machine-learning-without-phd) in San Francisco on November 13th.
* Shioulin Sam will be presenting at [Data Science Wrangle UK](https://events.attend.com/f/1383790543) in London on November 20th, and speaking on *Learning with Limited Labeled Data* at [ODSC London](https://odsc.com/london/europe-schedule/) on November 21st. 

If you're attending any of these events, please let us know - we'd love to say hello!   Reach out anytime to [cffl@cloudera.com](mailto:cffl@cloudera.com).

All the best,
The Cloudera Fast Forward Labs Team
