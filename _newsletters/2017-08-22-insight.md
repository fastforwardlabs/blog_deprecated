---
layout: newsletter
slug: 2017-08-22-insight
---

Hello!

Creative use of cereal boxes, colanders in the streets â€” we hope you enjoyed the (partial) solar eclipse if you were, like our Brooklyn office, within its path. In this week's newsletter, we take a look at the ICML 2017 award winning paper on model interpretability through influence functions and the curious story of Google Glass' demise and resurrection, as well as soccer playing robots (and why they matter).

Enjoy!

---

## Model interpretability via influence functions

Model interpretability is important in data science and machine learning, as we recently [argued](http://blog.fastforwardlabs.com/2017/08/02/interpretability.html).  *Model-agnostic* interpretability allows us to understand and explain any trained model. [LIME](https://arxiv.org/pdf/1602.04938.pdf), for example, which we cover in our most [recent research report](http://blog.fastforwardlabs.com/2017/08/02/interpretability.html), uses perturbation and local, sparse linear models to explain individual predictions of complex, high-accuracy models in terms of the *variables* that matter most for a given to-be-explained prediction.

This year's ICML best paper award went to ["Understanding black-box predictions via influence functions,"](http://proceedings.mlr.press/v70/koh17a/koh17a.pdf) an approach to model-agnostic interpretability complementary to LIME. The authors trace model predictions through the learning algorithm back to its training data to identify the *training data points* (vs. variables) most responsible for a given prediction.

To learn the effect of individual data points on model behavior, we could omit data points from the training data and note differences in the resulting model. But model training is expensive; this approach is, on a practical level, not feasible. Influence functions, around [since the 1980s](https://experts.umn.edu/en/publications/characterizations-of-an-empirical-influence-function-for-detectin), provide a workaround by telling us how model parameters change as we upweight a training point by a certain amount, but influence functions require expensive second derivative calculations and assume model differentiability and convexity; many modern models are non-differentiable, non-convex, and high-dimensional.

The contribution of the paper is to bring influence functions into the 21st century; specifically, the ability to use influence functions in combination with neural networks. The authors leverage [efficient approximation of second-order (partial) derivatives](https://arxiv.org/abs/1602.03943), using conjugate gradients and stochastic estimation, which may sounds complicated, but is easy to implement in standard auto-grad systems like *TensorFlow* and *Theano*. Through a series of experiments, the authors demonstrate that influence functions still yield meaningful results even with non-convex objective functions - which is important, since objective functions of neural networks are (highly) non-convex. Smooth approximations of non-differentiable losses allow us to use influence functions with hinge loss or [rectified linear units](https://www.quora.com/What-is-special-about-rectifier-neural-units-used-in-NN-learning) that cause non-differentiability in neural networks. In short, influence functions can help explain trained neural networks through the lens of their training data.

### Model interpretability for identification of domain mismatch
When the distribution of data that a model was trained on (i.e., the training distribution) does not match the distribution of data the model is tested on (i.e., test distribution), even a high accuracy model will perform poorly; this is called domain mismatch. Model interpretability through influence functions allows us to identify the training data *most* responsible for domain mismatch; it helps us understand and mitigate domain mismatch (a common occurrence in, e.g., the biomedical field where different hospitals serve different populations of patients).

### Model interpretability for fixing mislabelled data
Real-world labels are noisy, especially if crowd-sourced, and can adversely affect a model during training. Finding errors is a needle-in-a-haystack proposition. Influence functions pick out the training examples that exert the most influence over the model, flagging those for examination, because those are the cases where faulty labels would cause the most trouble for the model overall.

### Model interpretability for adversarial samples
A better understanding of the data points that matter for a trained model also allows us to generate trainig data that, if provided during model training, can flip predictions on test data (i.e., adversarial training samples). The authors demonstrate that, by perturbing only two images that were a part of the training set, they can flip the predictions of an image classifier on 77% of test images; they provide a strategy to hack trained models strategically and expose a vulnerability.

![Dog/Fish]({{ site.github.url }}/images/2017/08/dog_fish-1503352020658.jpeg)

##### Adversarial examples exploit areas of low certainty. Here, a training image that contains both a dog and a fish leads to less confidence in the model around these labels, and opens up an opportunity for adversarial attack.

What would happen if we used adversarial samples proposed by influence functions and used them as part of a Generative Adversarial Network (GAN), like the ones that have been used to generate [artwork](https://medium.com/towards-data-science/gangogh-creating-art-with-gans-8d087d8f74a1). GANs work well at a superficial level but break down when details are important. Abstract art? [No problem](https://www.newscientist.com/article/2139184-artificially-intelligent-painters-invent-new-styles-of-art/). Landscapes? [Fine](http://www.businessinsider.com/google-street-view-into-pro-level-landscape-with-ai-2017-7). There is no 'right' number of branches' or 'correct number of colored blobs.' Faces? A couple of extra eyes do make them look funky.

![Portraits made by a GAN]({{ site.github.url }}/images/2017/08/gangough-1503364210499.png)

##### Portraits made by [GANGough](https://medium.com/towards-data-science/gangogh-creating-art-with-gans-8d087d8f74a1). Art, perhaps, but not naturalistic depictions of faces.   

GANs sometimes produce nightmarish versions of common objects that humans have no trouble perceiving as incorrect. Could influence functions help guide the generation of samples during GAN training to strategically explore difficult areas? Influence functions add an important tool to the interpretability toolkit, as well as opening up a very promising avenue for future research.

![Fallout-Cow]({{ site.github.url }}/images/2017/08/fallout_cow-1503351768377.jpeg)

##### The aptly-named ['fallout cow'](https://arxiv.org/pdf/1701.00160.pdf) in the lower left.

---

## On finding the best, first use case: the tale of Google Glass

Google Glass was first launched on April 2013, and for a moment it looked like William Gibson's [visions of occular implants](http://www.williamgibsonbooks.com/blog/2006_08_01_archive.asp#115688201954919109) had once again proven [prophetic](http://www.newyorker.com/books/page-turner/william-gibsons-man-made-future). Presenting the world with a product that combined wearable technology with augmented reality before either of these applications had a strong foot on the ground, Google Glass seemed poised to change how we experience and interact with the world &mdash; while making Google X (now simply [X](http://money.cnn.com/2016/01/18/technology/google-x-new-logo/index.html)) some money along the way. 

Production of Google Glass however, stopped on January 2015. Since then, lots of reasons have been given as to why the product did not live up to the hype: from [privacy and regulatory considerations](https://www.fastcompany.com/3009432/tracking-the-ban-on-google-glass), to its [prohibitive price-tag](http://wearablecameras.com/reviews/google-glass-steep-price-worth-ultra-fancy-gadget/), and [restrictive societal norms](http://nypost.com/2014/07/14/is-google-glass-cool-or-just-plain-creepy/). The latest chapter of the saga, however, points in another direction: strategy, or (perhaps) its absence (which [Forbes](https://www.forbes.com/sites/ianaltman/2015/04/28/why-google-glass-failed-and-why-apple-watch-could-too/#3e6483544c4b) stated early on).

Apple taught many in the business world the importance of [early adopters](https://en.wikipedia.org/wiki/Technology_adoption_life_cycle) during product development and product launch. The omnipresent diagram of consumers divided into early-, mid-, and late-adopters of new technology has become something of an obsession in the start-up world. But while the success of Apple should be attributed to focusing on and providing for [consumer needs](http://appleinsider.com/articles/16/10/05/five-years-after-steve-jobs-an-apple-with-the-courage-to-say-no), Google Glass' (initial) demise seems to have been tied to confusion as to what purpose the product served. Google X relied on the ingeniousness of its early adopters, the '[Explorers](https://www.forbes.com/sites/tarunwadhwa/2014/04/24/the-google-glass-explorer-program-was-a-social-experiment-that-backfired/#527797685d95),' to figure it out. But they didn't. Maybe.

While Google Glass flopped as a lifestyle gadget, it was slowly and silently finding its home as a productivity tool within the enterprise: 'Google Glass Enterprise Edition' was launched just last month (July 18th), and is now marketed as a productivity-enabling technology. According to their new [website](http://www.x.company/glass/), this space is (suddenly) rife with applications, from hands-free instructions for workers on the assembly line, to remote consultation on technical problems and smart record-keeping, to automatic scanning of barcodes and workflow improvement. Imagine a company's personal assistants scanning, faxing, and e-mailing documents in the blink of an eye and as fast as they can say "sent," or firefighters being shown a secure path to safety while carrying an unconcious citizen through a building full of smoke. In combination with video and image analysis, wearable AR could help increase success rates in operation theaters and improve medical diagnoses. It could also identify and superimpose the items of my flatpacked IKEA desk onto a 3D image of the final, assembled product.

As more companies try to 'disrupt' industries with an innovative product or algorithm, the simple rule of business - "solve a problem and do it well" - rings more true today than ever. Technology by itself is not a solution to a problem; it's mere potential. Identifying the best, first use case for novel technology can be a struggle, especially for technology companies with little expertise in, say, manufacturing or firefighting. (Amazon's strategy is based on providing the first use case for its products (e.g., AWS) in-house, some say a strategy that motivated the purchase of Whole Foods.) In fact, the first incarnation of Google Glass may not have failed. Instead, it may have reflected recognition by Google that it is hard to identify the best first use case (or the best partner for the first use case) for novel technology without extensive and expensive market research and user testing. Google outsourced market research with the Explorers' program, and it seems to have worked. 

As the range of applications for AR is being defined, we should expect these products to become increasingly present in our everyday lives, first at work and eventually at home. Apple is following suit with its [just published patent](http://appleinsider.com/articles/17/07/27/apple-invention-details-ar-mapping-system-for-iphone-head-mounted-displays) for its own brand of AR products.

---

## Bend It Like Who Now?
When it comes to games, we often think of machine learning and AI in relation to video - but [this real-life robotic soccer tournament](https://www.robocup2017.org/eng/leagues_football.html) has a lofty goal (pun intended): according to [a recent article in the Smithsonian](http://www.smithsonianmag.com/innovation/why-funny-falling-soccer-playing-robots-matter-180964260/), the aim is to develop a team of robots by 2050 that can take down the reigning World Cup champions.  

![soccer playing robots]({{ site.github.url }}/images/2017/08/soccer_robots-1503364162730.jpg)

[As you can see from this (adorable) video](https://youtu.be/OYm_9ifChFc), they've still got a ways to go, but the technology required is far more complex than one might think.  Each robot must not only "think for itself" (being "aware" of its own surroundings and keeping its balance while playing the game), but also learn to work in conjunction with others - a feat which even we humans can sometimes find difficult.  These small playing fields are the testing ground for important work that could have long-term applications in multiple fields.

As technology continues to develop, more and more use cases for ML and AI application will continue to emerge, sometimes in industries where we may have least expected it.  Algorithms are already hard at work in [wildlife conservation](https://www.oreilly.com/ideas/from-binoculars-to-big-data-citizen-scientists-use-emerging-technology-in-the-wild) and [sleep studies](http://news.mit.edu/2017/new-ai-algorithm-monitors-sleep-radio-waves-0807).  What's next? The reaches of our imaginations and time may be the only limiting factors.

---

## Jobs, Jobs, Jobs

Here's a job opportunity for a data scientist:

**Enigma** - Data Scientist ([job description](https://www.enigma.com/careers/data-scientist))

We're always happy to share opportunities we hear about; please let us know if you have any you'd like for us to pass along.

---

## FFL Talks

We're giving talks at some upcoming conferences:
- [Synaptech](http://synaptech.ai/): September 21-22 **(Berlin, Friederike)** (Use the code 'FriederikeVIP' for a 30% discount!)
- [Strata Data Conference](https://conferences.oreilly.com/strata/strata-ny): September 28 **(New York, Hilary)**

As always, thank you for reading.  We'd love to hear your thoughts! You can reach us anytime at contact@fastforwardlabs.com. 


-- The Fast Forward Labs Team
