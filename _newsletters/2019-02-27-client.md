---
slug: 2019-02-27-client
layout: newsletter
---

## Natural Language Modeling and Transfer Learning (and Bluster?)

_by [Ryan](https://twitter.com/jqpubliq)_

Natural language processing has taken leaps forward lately as researchers have gained insights into better representations of language, i.e. embeddings, in deep neural networks. Several machine learning research groups have announced and/or released models and code that comprise a new generation of approaches to NLP. Some of the most well known of these are [GPT](https://blog.openai.com/language-unsupervised/) and [GPT-2](https://blog.openai.com/better-language-models/) by [OpenAI](https://openai.com/), [ELMo](https://allennlp.org/elmo) by the Allen Institute at the University of Washington, and [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) by Google.

![]({{ site.github.url }}/images/editor_uploads/2019-02-28-174441-universal_studios_singapore_2413365_640.jpg)
##### Image by ScribblingGeek on Pixabay

My colleagues Shioulin and Seth have written about the [differences among these approaches](https://blog.fastforwardlabs.com/2018/12/28/finetuning-for-natural-language-processing.html) and how they operate, and how they can be applied and improved [with transfer learning](https://blog.fastforwardlabs.com/2018/08/29/breakthroughs-in-transfer-learning-for-nlp.html).

On a less technical level, it's noteworthy that OpenAI *announced* its GPT model, touting its performance and sophistication. But they didn't *release* that model. Rather, they released a smaller, less sophisticated model, GPT-2 (without data and with only some code). They reasoned that the more complex model, GPT, is simply so powerful that it is too dangerous to release. OpenAI refers to their withholding of the full GPT model as "responsible disclosure."

This decision rings of hype, but [perhaps their model is indeed powerful enough to cause trouble](https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2). Natural language processing and natural language generation do - or will - have the potential to enhance existing capabilities to levels that make them more useful, but also perhaps more dangerous. 

* Chatbots - useful for customer service, but also useful for, e.g., conning victims out of money.

* Text assistance - useful for helping a specific author to write in her own style and voice, but also useful for e.g., allowing anyone to write in that style and pass off their writing as coming from that author.

* Text generation - useful for autogenerating simple text, e.g., financial results announcements in financial news, but also useful for generating "fake news" or spam ([although it may also, hilariously, fight spammers](http://digg.com/2017/re-scam-ai-scammer)).

OpenAI's true motive in releasing GPT-2 instead of the full GPT probably falls somewhere between hype and a safety-mandated withholding. It likely has real concerns that in its view warrant keeping GPT to itself, particularly in light of [similar issues in the visual space](https://en.wikipedia.org/wiki/Deepfake). But the decision is not made in a vacuum. OpenAI is well aware of the hype and fear around machine learning these days, and the attention drawn by headlines about an "AI" that is "too dangerous for the world" doesn't hurt; it's good publicity.

But in any event, I respect that OpenAI is even considering the ethics of the tools it puts into the world. To the extent they are relying on hype for publicity, I hope that they aren't contributing to another AI bubble of unmeetable expectations. But kudos for giving thought to what they put out in the world, and doing the most they think they responsibly can to advance the research without causing harm.

Whether it's overhyped or not, there *is* real promise in natural language processing in the coming months and years, especially with transfer learning. Given the new capabilities enabled by this generation of models and techniques, the likely breakthroughs in the area, and research momentum toward even more new capabilities, we've decided that the topic is ripe for a technical deep dive. To that end, here at Cloudera Fast Foward Labs, we are working on a report specifically on natural language processing with transfer learning. That report and an explantory prototype (we build at least one [with every report](https://www.cloudera.com/products/fast-forward-labs-research/fast-forward-labs-research-reports.html)), will be available later this year.

---

## Upcoming Events

* Hilary Mason will be speaking at the [Dataworks Summit](https://dataworkssummit.com/barcelona-2019/) in Barcelona, Spain on March 21st.
* Chris Wallace will also be speaking at the [Dataworks Summit](https://dataworkssummit.com/barcelona-2019/) on [Federated Learning: Artificial Intelligence and Data Science](https://dataworkssummit.com/barcelona-2019/session/federated-learning-artificial-intelligence-and-data-science/) on March 21st.
* Alice Albrecht will be speaking at the [Dataworks Summit](https://dataworkssummit.com/barcelona-2019/) as well, on "A Framework for Developing a Winning Data Project Portfolio" - date and time still TBD.
* Victor Dibia will be giving a talk called "Data2Vis: Automatic Generation of Data Visualizations Using Sequence-to-Sequence Recurrent Neural Network" at the [NVIDIA GTC 2019](https://www.nvidia.com/en-us/gtc/) in San Jose, CA on March 21st. 
* Mike Lee Williams will be speaking on [Federated Learning](https://conferences.oreilly.com/strata/strata-ca/public/schedule/detail/72661) at the Strata Data Conference in San Francisco on March 27th.
* Hilary will be speaking at the [Marketing Analytics and Data Science Conference](https://marketing.knect365.com/marketing-analytics-data-science/) in San Francisco, CA on April 10th.
* Mike will be chairing the "deep learning in practice" track at [Qcon.ai](https://qcon.ai/) in San Francisco on April 16-17th.

If you're attending any of these conferences, please [let us know](mailto:cffl@cloudera.com) and stop by to say hello! 

All the best,

The Cloudera Fast Forward Labs Team