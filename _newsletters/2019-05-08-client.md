---
slug: 2019-05-08-client
layout: newsletter
---

---

## Recommended Reading

Hello! In lieu of writing an article this week, we thought we'd share a few things that we've been reading.  Enjoy!

---
&nbsp;

#### [Unsupervised Data Augmentation](https://arxiv.org/abs/1904.12848)

_I like this paper because much of the exciting and impactful work in machine learning in the last couple of years involves doing more with less data. This discusses back translation, which is gaining a lot of steam, and the area of data augmentation for text and unsupervised methods is relatively uncharted. Also, it shows that it can be combined and complementary to transfer learning, which weâ€™re already very excited about. In particular, you can get state-of-the-art results for sentiment detection using just 20 examples! Remarkable._ - [Seth](https://twitter.com/shendrickson16)

&nbsp;

#### [Reinforcement Learning, Fast and Slow](http://bit.ly/2HcB4Ct)

_I like this paper because it highlights how borrowing from human cognition helps evolve our thinking of reinforcement learning. It focuses on addressing the slowness of traditional reinforcement learning with faster learning._ - [Alice](https://twitter.com/AliceAlbrecht)


&nbsp;

#### [Microsoft launches a new drag-and-drop machine learning tool](https://techcrunch.com/2019/05/02/microsoft-launches-a-drag-and-drop-machine-learning-tool-and-hosted-jupyter-notebooks/)

_Microsoft just released its own set of ML tools. One is a drag-and-drop autoML tool (look out, SAS), but there are  task-specific components like form data extraction, which are totally Microsoft's business-y jam._ - [Ryan](https://twitter.com/jqpubliq)

&nbsp;

#### [A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/)

_This is a concise checklist of tips and tricks for debugging neural networks._ -[Mike](https://twitter.com/mikepqr)

&nbsp;

![]({{ site.github.url }}/images/editor_uploads/2019-05-09-155640-tasks_2x.png)
##### Source: XKCD
&nbsp;

#### [Challenges of Real-World Reinforcement Learning](https://arxiv.org/abs/1904.12901)

_This paper lays out nicely why reinforcement learning is hard in real life, and precisely why we have yet to do a standalone report on it._ - [Shioulin](https://twitter.com/shioulin_sam)

&nbsp;

#### [AI Ethics: Seven Traps](https://freedom-to-tinker.com/2019/03/25/ai-ethics-seven-traps/)

_This article looks at the recent media and big tech attention to AI ethics through the critical lens of seven traps of thought that many commenters fall into. It claims (correctly, I think) that having a handful of rules or principles around AI ethics is insufficient to ensure ethical use of AI. In particular, that being ethical is an **activity**, not a **state**. I liked it because it goes beyond superficial and oft-repeated proclamations that AI ethics is important, and highlights why ensuring ethical use of AI is hard work._ - [Chris](https://twitter.com/_cjwallace)

&nbsp;

#### [Parametric Press Spring 2019 - Issue 01: Science and Society](https://parametric.press/issue-01/)

_This is the first issue of Parametric Press, a digital magazine where each article is an interactive explainer - featuring articles on JPEG compression, bias in machine learning, and particle physics. It makes me happy that people are exploring the power of interaction as a tool for understanding._ - [Grant](https://twitter.com/GrantCuster)

&nbsp;

#### [Google's distributed computing for dummies trains ResNet-50 in under half an hour](https://www.zdnet.com/article/googles-distributed-computing-for-dummies-trains-restnet-50-in-half-an-hour/)

_This article explains the work of several DeepMind researchers who thought distributed parallel ML computing has been way too hard for way to long and decided to do something about it.  _ - [Justin](https://twitter.com/JustinJDN)

&nbsp;

#### [MixMatch: A Holistic Approach to Semi-Supervised Learning - PDF](https://arxiv.org/pdf/1905.02249.pdf)

---

## Upcoming Events

Several of us will be at the Dataworks conference in Washington, D.C. on May 23rd! Here are the talks we'll be giving:
* Hilary Mason: _[Building an Enterprise AI Factory](https://dataworkssummit.com/washington-dc-2019/keynote/building-an-enterprise-ai-factory/)_
* Nisha Muktewar: _[Learning with Limited Labeled Data](https://dataworkssummit.com/washington-dc-2019/session/learning-with-limited-labeled-data-2/)_
* Alice Albrecht: _[A Framework for Developing a Winning Data Project Portfolio](https://dataworkssummit.com/washington-dc-2019/session/a-framework-for-developing-a-winning-data-project-portfolio-2/)_
* Justin Norman and Sagar Kewalramani: _[Machine Learning Model Deployment: Strategy to Implementation](https://dataworkssummit.com/washington-dc-2019/session/machine-learning-model-deployment-strategy-to-implementation-3/)_

and Shioulin Sam will be participating in a panel at NYC Media Lab's annual [Machines and Media](https://nycmedialab.org/machines-media-2019) event (also on May 23rd, here in NYC).

If you're attending Dataworks or the NYC Media Lab event, please [let us know](mailto:cffl@cloudera.com) and stop by to say hello! 


All the best,

The Cloudera Fast Forward Labs Team