---
layout: newsletter
slug: 2018-07-31-public
---
Hello! 

We are happy to announce that we recently published our latest research report
and prototype: *Multi-Task Learning*. Multi-task learning allows machines to
master more than one task at once and in parallel. It gives machines the
ability to benefit from task relationships. Machine learning becomes, a little
bit more, like human learning - capable of taking on more complex challenges
involving richer representations of reality. 

Enabled by multi-task learning, our prototype, *Newsie*, provides users with a
window into the differences in coverage and language use across the buttoned-up
and sensationalist press; it puts current news into perspective.

The ability to perform a fine-grained analysis of the news is just one way of
using the emerging capabilities of multi-task learning. Our report and
prototype are valuable for anyone looking for better solutions to complex
classification problems, efficient model performance, reduced model
maintenance, or the ability to train one model on several different, related
sets of data (as we did for Newsie). Multi-task learning has many benefits,
some of them quite subtle, but no less powerful.

For a very brief introduction to multi-task learning, have a look at the
[report
announcement](http://blog.fastforwardlabs.com/2018/07/24/ff08-launch.html) on
our blog. If you're curious about the successes of multi-task learning to date,
you can read about them
[here](http://blog.fastforwardlabs.com/2018/06/26/supercharging-classification-the-value-of-multitask-learning.html).
And, for a more in-depth introduction, watch a replay of our recent
[webinar](https://www.cloudera.com/products/fast-forward-labs-research/fast-forward-labs-research-reports.html)

Interested in accessing the report?
[Register](https://www.cloudera.com/products/fast-forward-labs-research/fast-forward-labs-research-reports.html)
to learn more about our Advising &
[Research](https://www.cloudera.com/products/fast-forward-labs-research/latest-research.html).

We hope you enjoy this month's newsletter, featuring the newest research into model
interpretability, topic models, and - a treat - neural (re)interpretations of
movie trailers.  

---

## Progress in machine learning interpretability
 
Our goal when we do research is to address capabilities and technologies that
we expect to become production-ready in one to two years. That focus on
fast-moving areas means that new algorithmic ideas sometimes come along that
allow our clients to extend or improve upon the work in our reports.

We published our report on machine learning interpretability last year. The technical focus of our report was LIME, a tool that computes locally
correct explanations of a model's behaviour. If a model is good, LIME's
explanations can offer completely new insights. (We saw this in our prototype,
which models customer churn using traditional machine learning techniques, but
then uses LIME to say precisely what it is about a customer that makes them a
churn risk.) And if a model is bad, LIME can help you understand why.

This all sounds great, but we had to leave three issues unresolved in our
report. Progress since last year has begun to address those concerns.

![](/images/2018/07/lime-1530894622923.png)

##### LIME explanations of sentiment classification. "Not" is a positive word in one example, but not in another. Image credit: [Anchors](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf).

Firstly, LIME's explanations are local. For example, a LIME explanation may
(correctly) tell you that "This movie is not bad" has positive sentiment
because it contains the word "not." But because LIME's explanations are local,
a user is not generally entitled to conclude from this that the word "not"
always indicates positive sentiment. This makes sense: the presence of "not" in
"this movie is not very good" does not tell you its sentiment is positive! But
how local is "local"? How similar to the original sentence does a new sentence
need to be for LIME's explanation to apply?

![](/images/2018/07/anchor-1530894675267.png)

##### Anchors explanations of sentiment classification. "Not" is a positive word in combination with "bad." Image credit: [Anchors](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf).

The creators of LIME offer an answer to this question in the form of [_Anchors:
High-Precision Model-Agnostic Explanations_(PDF,
2.7MB)](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf)." Anchors works
like LIME in that it probes the behaviour of the black-box model by perturbing
the original example. But it takes a very different approach to constructing a
human-friendly explanation. Rather than fit a locally correct linear model
(which raises the question: how local?), it constructs a set of rules. For the
"this movie is not bad" example above, the rule might be "sentence contains
'not' _and_ 'bad'". Such black and white rules are easier for many people to
understand than quantitative weights. And they implicitly define locality: if
the sentence doesn't contain "not" or "bad," the rule (and the explanation)
doesn't apply. The [Anchors code is publicly
available](https://github.com/marcotcr/anchor).

![](https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_instance.png)

##### [SHAP](https://github.com/slundberg/shap) explanation of a prediction for a model of the Boston house price dataset.

Secondly, LIME's choice of perturbation strategy and its local linear model are
heuristics -- which is to say they feel a little arbitrary, and it's reasonable
to wonder whether they are optimal in practice. In [A Unified Approach to
Interpreting Model
Predictions](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf)
Lundberg and Lee carefully define what we mean by optimal, and show that LIME
is a specific example of a more general class of explanation tools they call
"additive feature attribution methods." This class includes the classical
"Shapley" feature importance measure familiar to economists, and
[DeepLIFT](https://github.com/kundajelab/deeplift), a neural network
interpretability tool. They unify this class in a provably optimal way they
call [SHAP](https://github.com/slundberg/shap). The code is public, and is
[highly optimized](https://arxiv.org/abs/1802.03888) for the particular case of
tree-based methods such as XGboost. One thing we really like about SHAP is that
the built-in visualization tools are very nice! This seemingly minor point is
surprisingly important to the adoption of new tools, and we're glad to see
these authors spend time on this aspect of their code.

Finally, how do we _test_ explanations? How do we know whether an explanation
is evidence of a problem with the model or a surprising insight? Patrick Hall
and colleagues at [H2O.ai](https://www.h2o.ai/) sum up the current situation very well in a new
article for O'Reilly [Testing machine learning interpretability
techniques](https://www.oreilly.com/ideas/testing-machine-learning-interpretability-techniques).
The conclusion is: "use more than one type of tool to explain your machine
learning models, and look for consistent results across different explanatory
methods." We agree, and we're glad to see new options such as Anchors and SHAP
that make this easy!

So, a year after our report, machine learning interpretability remains not only
a very useful business capability, but a vibrant area of research. 

---

## Neural reinterpretations of movie trailers

In his latest project, artist and coder Mario Klingemann uses a neural network to match archival movie footage with the content of recent movie trailers. He regularly posts the resulting “neural reinterpretations” on [his Twitter](https://twitter.com/quasimondo). The results are technically impressive. They’re also a fascinating view into how to explore the creative possibilities of a machine learning technique.

Looking through Klingemann’s tweets you can trace his explorations:

![A screenshot from Klingemann's video of similar scene classification. A 3x3 grid shows several similar looking scenes. Some have planes, others are mostly blank, some have spare drawings of squares.]({{ site.github.url}}/images/editor_uploads/2018-06-26-144731-Screen_Shot_2018_06_25_at_10_45_15_AM.png)

##### Mario Klingemann's neural scene classifier grouping scenes it finds similar.

- Early in the explorations he posted [clusters of similar frames and clips in a 3x3 grid](https://twitter.com/quasimondo/status/1006485457713197056).
- He then experiments with compilations, like [scenes of water flowing (and other scenes the model thinks look similar to water)](https://twitter.com/quasimondo/status/1006570368751099904).
- Then he adds an element of interactivity, using [his webcam as the source against which to match the archival footage](https://twitter.com/quasimondo/status/1006835734223970304).
- He tries using the matches to create [new reaction gifs](https://twitter.com/quasimondo/status/1006996750429761536).

![On the left is a shot of Brad Pitt from Fight Club; on the right is a man holding a telephone with a similar expression from the archive footage.]({{ site.github.url}}/images/editor_uploads/2018-06-26-144942-Screen_Shot_2018_06_25_at_10_46_42_AM.png)

##### A neural reinterpretation of the Fight Club trailer, with the original footage on the left and the matched on the right.

- Then he moves into the trailer reinterpretations, with both stand-alone reinterpreted versions ([Fight Club](https://twitter.com/quasimondo/status/1010189455997784065)) and side-by-side versions ([Fight Club side-by-side](https://twitter.com/quasimondo/status/1010191619042238465)).
- He does [another version of the Fight Club trailer](https://twitter.com/quasimondo/status/1010983581475360768) using a tool that allows him to select from several algorithm-supplied suggestions: 

The movie trailer reinterpretations are a great showcase for the technique for a couple of reasons:

1. Trailers are made up of short clips. This gives the algorithm lots of shots at finding interesting matches (every cut is a new example). If it was instead focused on a 2 minute long continuous scene, you wouldn’t get to see nearly as many matches. Also the fact that the cuts are often timed to the music makes the reinterpreted content appear more connected to the audio of the trailer.

2. Films have a built up vocabulary of what different shots mean, like a close-up of a face to signal intense feelings. Film-makers employ these patterns consciously. As film watchers, we may not think about scene types explicitly, but we do build up associations and expectations with different framing, movements, and styles. The side-by-side reinterpretations make this referential language more visible by showing us two examples at a time, helping us notice the similarity the machine has identified. We can then often extrapolate even further into “ah, right, that’s another one of those 'vehicles rushing by' shots” that you normally don’t consciously note. This takes the trailers from technical demos into artistic territory.

![A screenshot of the video by Memo Atken. On the left is a blanket being scrunched up by hands; on the right is an image that looks like a painting of waves, where the shape of the waves matches the position of the hands and blanket.]({{ site.github.url}}/images/editor_uploads/2018-06-26-145050-Screen_Shot_2018_06_25_at_10_47_09_AM.png)

##### A still from "Learning to see: Gloomy Sunday" by Memo Atken

["Learning to see: Gloomy Sunday"](https://vimeo.com/260612034) by Memo Akten explores similarity in a different, fascinating way. He has a model trained on specific types of art that interpret his webcam photos and generate new images: for example, a sheet becomes waves. Like in the trailer reinterpretations, what takes this beyond technical demo is how suggestive the association can be. The machine's ability to identify similarity between a sheet and a wave gives us an understanding that we can then apply outside of the context of the video. It’s a suggestive analogy that opens out so that the viewer can build upon it and make their own connections.

---

## New Dynamics for Topic Models

Topic models can extract key themes from large collections of documents in an unsupervised manner, which makes them one of the most powerful tools in organizing, searching, and understanding the vast troves of text data produced by humanity. Their power derives, in part, from their in-built assumptions about the nature of text; specifically, to identify topics, the model has to give the notion of a topic a mathematical structure that echoes its significance to a human reader. In their recent paper, [*Scalable Generalized Dynamic Topic Models*](https://arxiv.org/abs/1803.07868), Patrick Jähnichen, Florian Wenzel, Marius Kloft, and Stephan Mandt show scalable models that allow topics to change over time in a way that is more general than it was previously, extracting new forms of patterns from large-scale datasets. 

### Probabilistic Topic Models: from Static to Dynamic 
Jähnchen et al.'s work builds on the shift towards probabilistic topic models that was cemented by the publication of David Blei, Andrew Ng, and Michael Jordan’s seminal [*Latent Dirichlet Allocation (LDA)*](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) in 2003. The context, at the time, was given in particular by [*Latent Semantic Indexing (LSI)*](http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf) (1990), which relies on finding linear combinations of [*tf-idf*]( https://en.wikipedia.org/wiki/Tf%E2%80%93idf) features that explain the greatest amount of variation in a corpus. Topics, in that case, are then weighted collections of words that are particularly discriminative with respect to identifying individual documents in the corpus, and finding them requires the singular value decomposition of a document matrix.

In contrast, [probabilistic topic models](https://cacm.acm.org/magazines/2012/4/147361-probabilistic-topic-models/fulltext#F1) rely on reverse engineering an imagined statistical process that generates the documents, in which the topics are latent parameters that are inferred from the raw corpus data. The generative process for LDA, for example, is a hierarchical Bayesian model that assumes that each word within a document is drawn from one of several multinomial distributions that correspond to topics. The mixture of topics in each document, i.e. the probability with which one of the multinomial distributions will give rise to a word in the document, is in turn determined by drawing from a Dirichlet distribution. Writing this out results in an intractable expression for the probability of each word, which is conditional on the topic parameters and can be fitted to the corpus using a host of well-known methods (as well as, conveniently, packages like [gensim](https://radimrehurek.com/gensim/models/ldamodel.html) and [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#sklearn.decomposition.LatentDirichletAllocation)). 

Of course, the inference process is considerably more difficult than the linear algebra required of LSI, but the process of designing a generative process makes it possible to imbue the topics with properties that highlight aspects of interest, or that make the topic model more realistic. For example, one might allow for topics to be correlated in the way that they co-occur within a document. At the expense of having to fit additional parameters, this enables surfacing [topic relationships](http://people.ee.duke.edu/~lcarin/Blei2005CTM.pdf). 

With [Dynamic Topic Models](https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf) (2006), David Blei and John Lafferty revisited the LDA process to tackle the problem of topics changing over time. While the original LDA model ignores any ordering of the documents in the corpus, dynamic topic models will take their time stamps into account. Blei and Lafferty did so by allowing the topic parameters to wander over time, specifically by imposing upon them a [Wiener Process](https://en.wikipedia.org/wiki/Wiener_process), also known as Brownian Motion. The results are highly compelling: in their [paper](https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf), they analyze over a century of *Science* magazine articles, and automatically extract a small history of neuroscience and atomic physics. (Blei happens to be an excellent lecturer, and those looking for his talks online will find a more [comfortable introduction](https://www.youtube.com/watch?v=FkckgwMHP2s) to ideas in topic modeling than is provided by the technical papers.)

![]({{ site.github.url }}/images/2018/07/f5-1531838383022.jpg)
##### Time Evolution of two topics within the Science corpus. From: [D. Blei, Probabilistic Topic Models,  Communications of the ACM (2012)](https://deliveryimages.acm.org/10.1145/2140000/2133826/figs/f5.jpg)

### Scalable New Dynamics
A Wiener process is convenient in several ways. It describes a random walk in which the value after each time step is simply the last time step, plus a random increment that is drawn from a normal distribution. In case of the LDA topic model, this allows for the multinomial distributions that represent the topics to undergo an incremental drift. In this way, the topics can change, albeit slowly enough to draw statistical robustness from older document data. The simplicity of the Wiener process also introduces temporal dynamics with the minimum number of additional parameters, and, given the difficulty of performing scalable approximate inference on topic models that implement dynamical stochastic process priors, had so far been the only process for which inference was feasible.

Jähnchen and colleagues now managed to substantially extend the spectrum of time dynamics to the general class of [Gaussian Processes](https://en.wikipedia.org/wiki/Gaussian_process), of which the Wiener process is the simplest subcase. Gaussian processes are completely defined by their mean and covariance function in the same way in which a Gaussian distribution is completely defined by mean and variance, and just like the Gaussian distribution, they simultaneously represent the simplest interesting case and are extremely broadly applicable. In [the study](https://arxiv.org/abs/1803.07868), the authors proceed by exploring the new wealth of possible functions by implementing dynamic topic models based on a three common processes used in time series modeling, comparing each to the result based on the Wiener process. The processes, which represent a small subset of realizable properties,  include:

##### 1.	Ornstein-Uhlenbeck:  
Brownian motion in the presence of a mean reverting force (in physics, this would for example occur for a spring that is undergoing thermal noise).

##### 2.	Squared Exponential kernel: 
A process with a memory over several previous time steps, in which the correlation with past time steps decreases exponentially. That is, the process has a short-term memory that can be tuned by changing the decay length.

##### 3. Cauchy kernel:
A process that has memory, similar to the one that corresponds to the squared exponential kernel, but in this case, the correlation with past time steps decreases polynomially. The process has a long-term memory. 

Based on large scale datasets, the authors reveal that each of these approaches reveals qualitatively different phenomena, and conclude that they offer better performance along the lines of interpretability and usefulness, as well as perplexity measures. However, the greatest strength is likely the ability to flexibly experiment with different types of processes toward different tasks: processes with short-term memory can be used for event detection, whereas long-term memory has greater statistical strength. The mean-reversion property acts as a type of regularization that responds to small-scale changes and localized topics in time. Adding and multiplying kernels also results in valid kernels, enabling considerable fine tuning. While deferred to future work, periodic kernels should be able to detect recurring events. 

On the whole, playing with different processes enables practitioners to intuitively adapt and experiment with dynamic topic models to analyze time-stamped corpora in a targeted way, benefiting from the extensive experience that has been gathered by studying time series in general. Apart from growing in sophistication, topic models will also grow in diversity: as the authors indicated toward the conclusion of the paper, the selection of a prior is a modeling choice that helps reveal the effects that one searches for.

---

## Recommended Reading, Etc.

Here are a few of our more recent favorite finds:
* [Modeling User Journeys via Semantic Embeddings](https://codeascraft.com/2018/07/12/modeling-user-journey-via-semantic-embeddings/)
* [Design Patterns for Production NLP Systems](http://deliprao.com/archives/294)
* [Program Synthesis in 2017-18](https://alexpolozov.com/blog/program-synthesis-2018/)
* [Design Patterns for Production NLP Systems](http://deliprao.com/archives/294)

We'd also like to recommend this webinar: [Cloudera Now](https://www.cloudera.com/more/events/cloudera-now.html); it's a half-day, packed agenda highlighting some of our best customer case-studies, data use-cases, and engaging industry speakers.
With an impactful keynote lineup and breakout tracks for both technical and business audiences, Cloudera Now will focus on the "how," and the best practices to help guide organizations through their data-driven journey. Learn more and register [here](https://www.cloudera.com/more/events/cloudera-now.html?utm_medium=email&utm_source=organicsdr&utm_campaign=other&src=sdr&cid=70134000001T2ub&utm_content=Cloudera%20NOW_Organic_AMER_Webinar_2018-08-02).

---

## CFFL Updates

* Mike will be speaking on "Serverless for Data Scientists" at [Pybay](https://pybay.com/) in San Francisco, on August 19th. (Learn more about Mike's talk in [this interview](https://medium.com/pybay/meet-mike-lee-williams-serverless-and-its-relevance-for-data-scientists-ba5a6cd0862e).)

* Shioulin will be speaking on [Semantic Recommendations](https://conferences.oreilly.com/strata/strata-ny/public/schedule/detail/69260) at the Strata Data Conference on September 12th, and Friederike will be [speaking at Strata](https://conferences.oreilly.com/strata/strata-ny/public/schedule/detail/69365) on September 12th as well.

* Friederike will also be speaking at the [Data Science Salon](https://www.eventbrite.com/e/data-science-salon-nyc-tickets-40072527007) on September 27th here in NYC.

* Shioulin will be speaking at [ODSC Europe](https://odsc.com/london) in London in September.

* You can now also catch two of Friederike's recent talks online, from [RAAIS 2018](https://www.youtube.com/watch?v=7lvtoDfDvHs&feature=youtu.be) and a panel at [Curious 2018](http://www.sciencemag.org/custom-publishing/webinars/technology-breakthrough-year-compelling-science-driven-curious-minds).

* And don't miss this thoughtful article on putting ethical principles into practice in data science, co-authored by our very own Hilary Mason, with Mike Loukides and DJ Patil: [Doing Good Data Science](https://www.oreilly.com/ideas/doing-good-data-science).

As always, thank you for reading. We welcome your thoughts, feedback, and suggestions; please [drop us a note](mailto:cffl@cloudera.com) anytime!

All the best,

The Cloudera Fast Forward Labs Team
