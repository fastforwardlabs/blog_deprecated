---
slug: 2019-10-02-client
layout: newsletter
---

## Where does a concentration of resources leave machine learning adoption?

_by [Alice](https://twitter.com/alicealbrecht)_

We’re in an era in which data storage and compute have become commodities which most modern businesses rely on in one form or another. Over the last decade, a few major technology firms - that made early, big bets on providing data storage and services - have also slowly created a centralized power structure in which they have increasing and disproportionate influence. These companies are a subset of what’s been termed the “[frightful five](https://www.nytimes.com/2017/10/11/technology/the-frightful-five-want-to-rule-entertainment-they-are-hitting-limits.html)” - big tech firms, which have already proven their ability to undercut other industries without sacrificing or altering their main [revenue stream](http://theconversation.com/big-tech-isnt-one-big-monopoly-its-5-companies-all-in-different-businesses-92791). 

As enterprise adoption of machine learning grows rapidly, so does the reliance of most companies on Google, Amazon and Microsoft for the storage and tools to build data into their business. This reliance reinforces the power that these big tech firms have, allowing them to shape policy and market dynamics, and also increasingly dictates who can (and [who can’t](https://www.nytimes.com/2019/09/26/technology/ai-computer-expense.html)) afford to participate in machine learning research to shape the next wave. 

![]({{ site.github.url }}/images/2019/10/big_five_monopoly-1569945621234.png)
Caption: Photo credit to [the conversation](https://theconversation.com/big-tech-isnt-one-big-monopoly-its-5-companies-all-in-different-businesses-92791)

The growing concern around big tech firms isn’t new, and has even been brought into the current election cycle as Elizabeth Warren [calls for their break up]([Elizabeth Warren on Breaking Up Big Tech - The New York Times](https://www.nytimes.com/2019/06/26/us/politics/elizabeth-warren-break-up-amazon-facebook.html)) and was met [this week](https://www.theverge.com/2019/10/1/20756701/mark-zuckerberg-facebook-leak-audio-ftc-antitrust-elizabeth-warren-tiktok-comments) with scorn from Mark Zuckerberg himself. As it relates to machine learning in particular, the worry around general tech concentrations of power are combined with the dramatically [increasing cost](https://syncedreview.com/2019/06/27/the-staggering-cost-of-training-sota-ai-models/) of doing machine learning research and deploying machine learning models. This increasing cost means that those without big tech-sized compute and monetary resources won’t be able to contribute intellectually or economically (by developing new ML-powered products). This divide has been increasing steadily and has spawned many [hardware advancements](https://venturebeat.com/2019/09/21/the-ai-arms-race-spawns-new-hardware-architectures/) such as neuromorphic chips and optical computing that may eventually help re-level the playing field.   

Universities frequently lose their talent to big tech firms that offer increasing access to the storage and compute that’s necessary to do their work. Even non-academic groups are increasingly relying on big tech firms to continue their work. [OpenAI](https://openai.com/), which was originally a non-profit group that built a research team (attracting top talent) aimed at creating safe AI, recently became a capped-profit enterprise and partnered with Microsoft to support its continued research (and have access to vast Azure resources). As researchers are increasingly moving from academia to these big tech firms, in part to gain access to the compute resources necessary to do their work, universities will be stripped of their top machine learning talent (or their research labs will suffer from a lack of focused leadership) and the big tech firms will have lost their goose (and their golden eggs). 

Not only are the big tech firms the increasingly dominant option for building machine learning products inside other companies, these firms are creating products that are actually a fairly thinly veiled play at collecting more and more data for their own machine learning research. Just last week, Amazon [launched several products](https://blog.aboutamazon.com/devices/amazon-devices-event-september-2019) that are all input devices into the machine learning algorithms that power Alexa. As more and more data is amassed at big tech firms and the incentives when building new algorithms are for better accuracy, not enough care is given to the real cost of training and deploying these models (which includes the [environmental impact](https://arxiv.org/pdf/1907.10597.pdf) of ever more power-hungry algorithms). 

We as a field need to be keenly aware of the ways in which we support a tech oligarchy in data and machine learning and realize that we can build and use all of the open source tools we want, but at the end of the day, only those with increasingly vast resources can contribute to the advances in machine learning. This is _not_ to say that we should boycott big tech, but rather that we should be aware of the perhaps nuanced ways in which the future is being shaped - and who gets to participate in that. 

Things are not hopeless. The very fact that so much is being written and discussed around these issues is proof-positive. My hope in this newsletter is to help illuminate a current possible direction, and to suggest that this is a moment in which to change course. We’ve already seen the beginnings of algorithmic advances that decrease the resources needed for machine learning in our research on ways to use less labeled data to train machine learning models (see our blog posts [generally](https://blog.fastforwardlabs.com/), but especially those on [meta learning](https://blog.fastforwardlabs.com/2019/05/22/metalearners-learning-how-to-learn.html) and [active learning](https://blog.fastforwardlabs.com/2019/04/02/a-guide-to-learning-with-limited-labeled-data.html), and [transfer learning](https://blog.fastforwardlabs.com/2019/08/28/nlp-and-transfer-learning.html)). We expect advances to continue in this direction on both the hardware and software front in the years to come.

---