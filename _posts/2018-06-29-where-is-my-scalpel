---
title: Where is my scalpel? ML for surgical tool detection
date: 2018-06-29 12:08 -0400
preview_image: /images/2018/05/Retained_Medical_Devices_Surgical_Errors_Operation_Tools_Left_Inside_Body_X_Ray-1527712910412.jpg
feature: false
published: true
post_type: Newsletter
---

It may surprise some that surgical tools left behind in patients is a common problem, with thousands of reported cases in the U.S. alone each year. Machine learning for â€‹surgical tool detection has a multitude of useful applications ranging from generating operation reports, reconstructing surgical workflows, coming up with intervention systems that would provide real-time recommendations or warnings to the surgeon, inferring surgery phases based on tool presence and others. The construction of such a detection system is guided by a wide array of experiments that explore different design decisions.

A recent [paper](https://arxiv.org/pdf/1805.05760.pdf) discusses possible solutions and employs a 50-layer residual network (ResNet) architecture that can distinguish 21 different tools in [cataract surgery videos](https://cataracts.grand-challenge.org/data/). The authors explore various transfer learning approaches, either in the form of fine tuning (FT) or as a fixed feature extractor (FFE). When working with the FT network family, it uses all 49 convolutional layers of ResNet and the output feature maps of the 49th convolutional layer are either fed into the *avg-fc* or *conv-max* classification head. The *avg-fc* classification head is a standard global average-pooling followed by a fully connected layer and the *conv-max* uses a fully convolutional network and a global max-pooling layer. In general, all weights in this network family are trainable but for some experiments the first k layers of ResNet are frozen. Training this architecture requires a significant amount of memory due to the many trainable weights and input image resolution. On the other hand, the FFE network family uses the first k layers as a feature extractor with fixed weights. The resulting feature maps are fed to a max-pooling layer and three layers of convolutions with 384 feature maps each. Like for the first network family, the final part is either the *avg-fc* or *conv-max* classification head. Training this architecture is relatively inexpensive in terms of required memory because all ResNet weights are fixed and only the custom layers are trained. 

![]({{ site.github.url }}/images/2018/05/Retained_Medical_Devices_Surgical_Errors_Operation_Tools_Left_Inside_Body_X_Ray-1527712910412.jpg)
##### Don't lose your scalpel, or your scissors.

In both network families each output node corresponds to a predicted score for one of the *c* surgical instruments. Because the instruments are not mutually exclusive, the binary relevance transformation is used so that the task is treated as *c* separate binary classification problems.

Prior to the training process various pre-processing strategies are applied to the dataset. For instance, due to the nature of video, subsequent frames tend to be extremely similar to one another. Therefore, only every sixth frame of each video is used. Further, since a predecessor or successor of a frame is part of the training set, the validation error would be a significant underestimation of the test error if one were to split all the data randomly into train-validation. Hence, instead a split at the video level is performed. In addition, because some tools only appear in a single training video the variability between the frames showing such tools is low. To tackle this problem, several image augmentation techniques are employed.

In the end, the FT model instances perform better than the FFE ones which seems plausible as the cataract dataset is different than ImageNet. The *conv-max* classification head does not seem very useful and instead using a weighted loss fuction slightly improves the performance. The resulting network works exceptionally well for some tools but performance suffers in other cases because not enough training data is available. Nonetheless, it explores interesting solution design decisions!