---
layout: post
title: "60s Philosophy of AI revisited for 2017"
date: 2017-07-28 7:19
preview_image: /images/2017/07/dreyfus.gif
feature: false
author: Sepand
published: true
author_link: https://twitter.com/s3pans
---

![hubert dreyfus](/images/2017/07/dreyfus.gif)


[Hubert Dreyfus](http://news.berkeley.edu/2017/04/24/hubert-dreyfus/)[^1], UC Berkeley professor of philosophy, phenomenologist and continental philosophy scholar recently passed away. Apart from his works on Heidegger, Foucault and Merleau-Ponty, he was one of the pioneers in philosophy of Artificial Intelligence. His work was distinct from many other philosophers of AI, like John Searle and Daniel Dennett, in that he was not concerned as much about the philosophical [thought experiments](https://en.wikipedia.org/wiki/Chinese_room) about mind, intelligence and consciousness. His approach was more a practical one, asking about what is possible to achieve with machine intelligence and what is beyond machine’s capability in mimicking human intelligence due to their fundamental differences in forms of cognition and ‘being-in-the-world’. In that sense he was one of the first to think about non-human phenomenology, or what are the structures of ‘experience’ in non-human agents.[^2]

![What computers still can't do](/images/2017/07/what_computers.gif)

In 1972 he wrote the book ‘What computers can’t do’ on the philosophy of AI. As the title implies, it is mostly his criticism of what AI researchers had claimed to be achievable in a few years. It later turned out his arguments were in many cases correct, as he later renamed the book to ‘what computers **still** can’t do’ in 1974 and 1992 editions. The book is a bit too dated for someone who is not specifically interested in its historical context so we have summarized some takeaways to what matters in 2017:

### Humans are not symbolic inference machines

The main theme of his book is the criticism of first generation AI of 60s and 70s, which was mostly based on representation-based symbolic systems and knowledge-based logical inference. He argued that unlike a formal system which operates based on a set of rules, most of our cognitive capabilities, like recognizing objects or developing skills, are some sort of implicit know-how knowledge which we learn by dealing with enough similar situations, or imitation. He argued it is not possible to represent that kind of implicit knowledge formally, like a step by step algorithm. If there is an illusion of being able to do so, in many cases it is because we ‘think’ using language and formal linguistic structures, and whenever we ‘think’ about a skill we project the linguistic structures into that skill and get the impression that the knowledge of performing the skill itself has a formal structure.

The above criticism is no longer applicable to the current AI research. Neural networks, [Feature Learning](https://en.wikipedia.org/wiki/Feature_learning) and many other modern AI methods don’t rely on the ‘representation’ of knowledge; similar to humans, at the price of being a black box, similar to our brain. So while it might seem that Dreyfus’ work is something of the past, his core argument has more implecations.

## Humans don’t learn passively, nor should Machines.

Dreyfus argued that active involvement in everyday social practices creates the context for being able to have a cognitive feedback loop to perform and evaluate actions, and by doing that interpret the world. This active involvement requires every little detail and possibilities of interaction to build a framework for filtering what is relevant in every situation. For instance in the case of driving a car, we may judge by the model of the surrounding cars, or the bumper stickers on them, or the shops in the street, or even what has been on the news lately, to find the optimal way of driving. We are able to update the context of the actions and find the relevant information no matter how far fetched it might seem, thanks to our involved embodiment in the world.

We need to acknowledge data fed into a model is an abstraction of the inexhaustible reality. Collecting the data and making a model inevitably involves reducing that deep inexhaustibility into a manageable and computable finitude. Our brain does the same task as well, however an involved and embodied agent has the opportunity to actively revisit and refine what is bracketed out and develop new concepts. Many of today’s challenges of AI are rooted in the same fact that finding complicated higher level patterns requires recontextualizing otherwise it just look like noise.



For example in case of avoiding racism or discriminatory bias, the system may not have access to the context of socio-political history of past 300 years, to be able to identify complex human cultural behaviours like racism and discrimination to avoid them. It is true that in many cases where algorithms have discriminatory behaviour, the reason is bias in the training data, however as humans we also encounter situations where we are surrounded by biased information but our multi aspected embodied existence lets us, sooner or later, recognize and avoid that bias.

### Is Ethics constructed of given, or, can AI learn what is Good or Evil?

Dreyfus hasn’t covered ethics of Artificial Intelligence in details in his book, however we can try to follow his lines of thought and use the philosophy of thinkers like Soren Kierkegaard or Friedrich Nietzsche, who also influenced Dreyfus, and apply them on the problem of AI and Ethics.

We as humans are constantly creating concepts and re-interpreting, evolving and destroying them, and that is how we create a foundation for our actions. This foundation is the totality of every little activity we perform and expressions we utter socially in our shared perceptual and conceptual apparatus. We see and understand things and at the same time this understanding destabilizes and reconfigures the foundation of our beliefs to some extent. We create the moral ground for our actions by performing actions, which then justifies other actions. It seems like a chicken and egg problem but it really hints that learning things and morality are not two separate processes. In ‘[On Truth and Lies in an Extra-Moral Sense](http://nietzsche.holtof.com/Nietzsche_various/on_truth_and_lies.htm)’ Nietzsche describes it:

"Here one may certainly admire man as a mighty genius of construction, who succeeds in piling an infinitely complicated dome of concepts upon an unstable foundation, and, as it were, on running water. Of course, in order to be supported by such a foundation, his construction must be like one constructed of spiders' webs: delicate enough to be carried along by the waves, strong enough not to be blown apart by every wind. As a genius of construction man raises himself far above the bee in the following way: whereas the bee builds with wax that he gathers from nature, man builds with the far more delicate conceptual material which he first has to manufacture from himself."

So for humans, at least everyday ethics is not given but constructed. It is not a priori and  something above ‘learning’, controlling and governing it, neither the ground for it like [Asimov’s three laws of robotics](https://en.wikipedia.org/wiki/Three_Laws_of_Robotics). Humans develop their own ethics through situated social interactions. So the important question here is should AI be given our moral rules, at the price of being too limited, or be able to construct the ethical grounds. In the later case how much of that artificial ethics is common with ours? Or in either case can we even block AI from developing conflicting ethics?

----

[^1]:  Futurama’s Professor Hubert Farnsworth was named after Dreyfus.

[^2]:  (NOTE:  Bruno Latour, among others, has developed Actor Network Theory which tries to avoid anthropocentrism. Instead of putting humans in the center of every theory, create a way of thinking in which Actors, human or inhuman have the same ontological significance. Unlike Latour, Dreyfus’s work, similar to Heidegger's, put human existence, Dasein, superior to other forms of beings, but it was an attempt to see beings other than humans potentially at the same level as Dasein.)


