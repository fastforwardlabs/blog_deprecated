---
layout: post
title: "Why we talk about AI the way we do, and why we have to change it."
date: 2017-07-25 12:00
preview_image: TBA
author: Friederike
author_link: "https://twitter.com/FSchueuer"
feature: true
published: false
---

The public conversation about machine learning and AI happens at the extremes. [Elon Musk's worries about machine-learning overlords](http://www.vanityfair.com/news/2017/03/elon-musk-billion-dollar-crusade-to-stop-ai-space-x) motivated his companies [SpaceX](http://www.spacex.com/) (to escape to Mars; escapism), [Neuralink](https://www.technologyreview.com/s/604254/with-neuralink-elon-musk-promises-human-to-human-telepathy-dont-believe-it/) (to fuse with machines; oneness), and [OpenAI](https://openai.com/) (to create benevolent machines; coexistence). Nevertheless, conversations at the extremes are rarely productive. Instead, they prevent a more constructive conversation about the very real capabilities of AI today, its likely capabilities within the upcoming years, its associated problems and exciting opportunities. We have to move away from the extremes and change how we talk about AI. 

## Biases and their effects on discourse 
In cognitive psychology, there is a rich tradition of research on [human biases in decision making](https://en.wikipedia.org/wiki/List_of_cognitive_biases). We overestimate the probability of rare events, which is why people buy lottery tickets, and underestimate the probability of frequent events (i.e., probability distortion). We are sentitive to [anchoring](https://en.wikipedia.org/wiki/Anchoring), [survivership](https://en.wikipedia.org/wiki/Survivorship_bias) and [status-quo](https://en.wikipedia.org/wiki/Status_quo_bias) bias. The doom-and-gloom picture of the future of AI stems from the latter.

Status-quo bias, an emotional bias, is a preference for the current state of affairs. The current state of affairs is taken as the benchmark, and any change is perceived as a loss. Status-quo bias is also related to the endowment effect, the tendency to weigh potential losses of switching from the status quo more heavily than potential gains. The endowment effect is part of nobel laureate [Daniel Kahneman](http://www.nytimes.com/2011/11/27/books/review/thinking-fast-and-slow-by-daniel-kahneman-book-review.html)'s [Prospect Theory](https://en.wikipedia.org/wiki/Prospect_theory), which states that utility functions are steeper in the loss domain than in the gains domain. In other words, change in a negative direction is perceived to be more harmful than the same amount of change in a positive direction could be beneficial. Note that, in general, biases are taken to be instances of behavior that depart from a "rational observer" model (i.e., a reward maximizing observer), but not always. Status-quo bias can be rational, [some argue](http://www.journals.uchicago.edu/doi/pdfplus/10.1086/678482), especially when we have got [limited information about future events](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.545.5116&rep=rep1&type=pdf), as we often do and especially when it comes to the future capabilities of a technology we may not understand (machine learning, AI).

There is an an "imaginative" bias, too. It is simply easier for us humans to image things we know and things we have going away, disappearing. We fear their loss. It is much harder for us to imagine what we do not know, and what does not exist today, to exist in the future. We miss out on the excitement. As machine learning researchers and practitioners, we have the privilege to be better positioned to imagine what may not exist today but will exist in the future, exciting new capabilities and jobs for people, and hopefully a fairer, more equal society than the one we live in today. We have a more intimate knowledge of the machine learning tools and the AI capabilities they enable, that allows us to be better at extrapolation. We may feel uncomfortable taking the stage and "predicting the future", but as Albert Einstein once said: *"Those who have the privilege to know have the duty to act."* if we don't fill that vaccum others will, and we'll drift towards a conversation at the extremes with pronounced dystopianism.

## The only constant is change
Let's face it, today's society is already different from the one we lived in five, ten, twenty years ago. Personal computers as big as pocket calculators, the machine's capabilities long surpassed our's in some areas. Some of that change was driven by data and algorithms. 

Earlier in July, the News Media Alliance, a trade association representing approximately 2000 newspapers in the United States and Canada, [asked the US Congress for an exemption from antitrust law](https://www.newsmediaalliance.org/release-digital-duopoly/) to gain the rights to collectively bargain with Google and Facebook, who have taken over control of news media distribution and have started to eat into publishers' revenue. Access to good reporting, publishers say, is essential to a well functioning, democratic, human society, and they asked congress to protect it.

Google's and Facebook's control over the distribution of content has changed news (and content) consumption and not always for the better. [Fewer stories drive more traffic](https://www.theatlantic.com/technology/archive/2017/07/facebook-and-the-media/533079/) - everything is "spikier" now, for example. As a consequence, as publishers chase after "spikey pieces," articles tend to cluster around a few themes and news events that receive outsized attention at the expense of others (e.g., [covfefe](https://www.wired.com/2017/05/internet-defines-covfefe/)). Messages with [moral-emotional words are more likely to get retweeted](https://phys.org/news/2017-06-messages-moral-emotional-words-viral-social.html) and, writers change their language to deliver what is attractive at the time.

But the inconvenient truth is that over the past decade, few newspapers derived economic value from good reporting. Content had to be just good enough to attract eyeballs for advertisers to place their ads in the papers (the past is not always better than the present, sometimes its just the same). With Google and Facebook controlling the means of distribution, and gobbling up publishers' *advertisement* dollars, ad-supported business models may not be viable anymore in the publishing industry. How about a future in which quality publications support themselves through good reporting? Publications that spend the time and effort to understand their readers and research and write content to keep them informed. Some of these publications exist today.

## Embedded innovation, a conversation
The reason we specifically chose the example of increasingly emotional points of view in news and other public content, is that machine learning and AI innovation lives within legal and economic reality. If we don't acknowledge incentives, we will not be able to recognize neither impact and opportunity, nor potential downsides. [Content moderators](https://www.theguardian.com/news/2017/may/21/facebook-moderators-quick-guide-job-challenges), the human eyeballs to check machine-flagged content for objectionable text or images, scan through a lot of material every single day. We have to ask ourselves, how can a human being see the footage of [a man killing his 11 months old daughter](https://www.theguardian.com/technology/2017/apr/25/facebook-thailand-man-livestreams-killing-daughter), and walk away unharmed? There are challenges ahead regarding identifying and mitigating workplace hazards of new technology-enabled jobs.

Instead of getting distracted by scenarios of machine overlords, we should focus on opportunity, identify current and near-future challenges, and provide constructive solutions. Part of that solution will be to drive the public coverage of machine learning and AI away from the extremes to enable the general public to get a better sense of the real capabilities of machine learing and AI today and within the years to come. [Word embeddings](https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/), at the heart of many natural language applications today, are [known to be biased](http://www.sciencemag.org/news/2017/04/even-artificial-intelligence-can-acquire-biases-against-race-and-gender). We can [debias embeddings](https://arxiv.org/abs/1607.06520), but who will be the arbiter? When we move away from classifying cats, questions become more complex and we need to start taking into account diverse perspectives. We need to counter status-quo bias, the endowment effect, and imaginative bias to empower the public to understand, dream, and then work with us to share their perspective. We need to move away from the extremes in the conversation about machine learning and AI to tackle some of its hardest problems.
