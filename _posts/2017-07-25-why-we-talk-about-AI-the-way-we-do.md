---
layout: post
title: "Why we talk about AI the way we do, and why we have to change it."
date: 2017-08-02 12:00
preview_image: TBA
author: Friederike
author_link: "https://twitter.com/FSchueuer"
feature: true
published: false
---

The public conversation about machine learning and AI happens at the extremes. AI is either awesome or scary. It writes [movie scripts](https://arstechnica.com/the-multiverse/2016/06/an-ai-wrote-this-movie-and-its-strangely-moving/), wins at [poker](http://www.sciencemag.org/news/2017/03/artificial-intelligence-goes-deep-beat-humans-poker) and [Go](https://techcrunch.com/2017/05/24/alphago-beats-planets-best-human-go-player-ke-jie/), and helps [Google cool its data centers](https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/). Awesome! It will take our [jobs](http://www.eng.ox.ac.uk/about/news/new-study-shows-nearly-half-of-us-jobs-at-risk-of-computerisation) and robot investors will incite [wars for profits](http://fortune.com/2016/08/17/elon-musk-ai-fear-werner-herzog/). Scary!

Conversations at the extremes are rarely productive. They prevent a more constructive debate. To address the very real problems associated with machine learning and AI today, and to identify and build towards the exciting new futures that could be enabled by them, we have to change how we talk about AI. Specifically, we need to avoid the distraction of [dystopian doomsday scenarios](http://www.vanityfair.com/news/2017/03/elon-musk-billion-dollar-crusade-to-stop-ai-space-x).

### Everything is changing, always
Today's society is already different from the one we lived in five, ten, or twenty years ago. With personal computers the size of pocket calculators, machine capabilities have long surpassed our own in some areas, and plenty of that change was driven by data and algorithms. Machine learning and AI can help diagnose disease, achieving [higher accuracy of tumor classification on slides of lung cancer tissue](https://med.stanford.edu/news/all-news/2016/08/computers-trounce-pathologists-in-predicting-lung-cancer-severity.html) compared to human medical doctors, and self-driving cars promise to reduce the number of fatalities in traffic accidents.

In a changing world, dystopian doomsdays distract from opportunity. Data and algorithmic smarts allowed Google and Facebook to control the distribution of news media gobbling up publishers' advertisement dollars, the main source of income in the news media industry. This sounds dystopian, access to high quality reporting is important for a well-functioning democratic society, but consider a future in which quality publications support themselves not through advertisement but good reporting, an even better foundation for an informed citizenry. 

As dystopian doomsdays make us worry about fake challenges, they distracts us from solving real ones. We need to identify and mitigate workplace hazards of new technology-enabled jobs. During the industrial revolution, with the introduction of machinery, workers put their bodies at risk, and those risks needed to be addressed. There will be different risks to consider when it comes to machine learning and AI. [Content moderators](https://www.theguardian.com/news/2017/may/21/facebook-moderators-quick-guide-job-challenges), the "human eyes" that check machine-flagged content for objectionable text or images, scan through a lot of material every single day, putting their minds at risk as they view images and words that could cause harm. We have to ask ourselves, can a human being see the footage of a man killing his own child, as described in The Guardian's report on [the life of a Facebook content moderator](https://www.theguardian.com/news/2017/may/25/facebook-moderator-underpaid-overburdened-extreme-content), and walk away unharmed? 

These are the sorts of challenges we should consider and solve for today, rather than being distracted by future machine-learning overlords and our [escape to Mars](http://fortune.com/2017/06/15/elon-musk-spacex-mars-colony-paper/). The industrial revolution led to machines that could go down into coal mines, so that fewer miners lost life and limb as part of their jobs. The AI revolution may proceed similarly - and as it does, we should remember that the AI revolution does not "just happen." Instead, we make it happen. We should focus on opportunity, identify current and near-future challenges, and provide constructive solutions. It is we who build the future. 

### Cognitive biases explain dystopian doomsdays
Why do dystopian doomsdays take hold so easily in the public debate? Machine learning and AI, like any technology, can be used for good and bad. 

The doom-and-gloom reporting is driven by cognitive bias. Status-quo bias is a preference for the current state of affairs. The current state of affairs is taken as the benchmark, and any change is perceived as a loss. Status-quo bias is related to the endowment effect, the tendency to weigh potential losses of switching from the status quo more heavily than potential gains, and it is part of nobel laureate [Daniel Kahneman](http://www.nytimes.com/2011/11/27/books/review/thinking-fast-and-slow-by-daniel-kahneman-book-review.html)'s [Prospect Theory](https://en.wikipedia.org/wiki/Prospect_theory). Utility functions are steeper in the loss domain than in the gains domain. In other words, change in a negative direction is perceived to be more harmful than the same amount of change in a positive direction could be beneficial. 

We have an "imaginative" bias, too. It is simply easier for us to imagine the disappearance of things we know and with which we are familiar. We fear their loss. It is much harder for us to imagine the existence of things in the future that we do not know and which do not exist today. Losses loom larger than gains. We are biased against excitement.

Generally, biases like the status-quo bias are taken to be instances of behavior that depart from a "rational observer" model (i.e., a reward maximizing observer), but not always. Status-quo bias can be rational, [some argue](http://www.journals.uchicago.edu/doi/pdfplus/10.1086/678482), especially when we have [limited information about future events](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.545.5116&rep=rep1&type=pdf), as we often do -- especially when it comes to the future capabilities of a technology that [we may not understand](https://techcrunch.com/2017/07/19/this-famous-roboticist-doesnt-think-elon-musk-understands-ai/). Dystopian doomsdays are driven by lack of understanding, a more nuanced conversation will remove the drivers of the doom-and-gloom reporting on AI -- a virtuous cycle. 

### Why it matters now more than ever
A more level-headed conversation about AI will remove the distraction of doomsdays and empower the general public to share their perspectives which has become increasingly important. In machine learning, we used to [classify cats](https://www.wired.com/2012/06/google-x-neural-network/). One's background, ethnicity, socioeconomic class, upbringing, and life experiences are unlikely to influence one's judgement of whether or not a given image is an image of a cat. We tend to agree on the concept of "catness." How about "fairness" or "unbiasedness" - concepts at the heart of [current machine learning research](https://arxiv.org/abs/1607.06520)? Who will be the arbiter? 

As we have started to move away from cats, the questions have become more complex, and truth has becomes harder to establish (if truth, as a concept, is even applicable) -- which is why we need to start taking into account diverse perspectives. We need to counter status-quo bias, the endowment effect, and imaginative bias to drive the public conversation about AI away from the extremes and avoid the distraction of dystopian doomsdays to empower the public to understand, dream, and share their perspectives. We need to move away from the extremes in the conversation about machine learning and AI to tackle some of its hardest problems -- together.
